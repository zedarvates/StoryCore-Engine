# Guide de T√©l√©chargement des Mod√®les Locaux

## üöÄ D√©marrage Rapide

### √âtape 1 : D√©marrer Ollama
```bash
ollama serve
```
Laissez cette fen√™tre ouverte pendant le t√©l√©chargement.

### √âtape 2 : Ouvrir la Console du Navigateur
1. Dans l'application, appuyez sur **F12**
2. Cliquez sur l'onglet **Console**
3. Gardez cette fen√™tre ouverte pour voir la progression

### √âtape 3 : T√©l√©charger un Mod√®le
1. Allez dans **Settings** ‚Üí **LLM Configuration**
2. S√©lectionnez **Local LLM**
3. Cliquez sur **Download** √† c√¥t√© du mod√®le souhait√©
4. Observez la progression dans la console et dans l'interface

## üìä Comprendre la Progression

### Dans l'Interface
- **Bouton "Download"** ‚Üí Le mod√®le n'est pas install√©
- **"Downloading... X%"** ‚Üí T√©l√©chargement en cours
- **Barre de progression** ‚Üí Pourcentage t√©l√©charg√©
- **Bouton "Installed"** ‚Üí Mod√®le pr√™t √† utiliser

### Dans la Console (F12)
Vous devriez voir des messages comme :
```
Starting download for model: gemma3:1b
Download progress data: {status: "downloading", completed: 1048576, total: 1610612736}
Download progress for gemma3:1b: {progress: 15.5, ...}
Download progress for gemma3:1b: {progress: 32.8, ...}
Model download completed successfully
```

## ‚ùå Probl√®mes Courants

### Probl√®me 1 : "Ollama is not running"
**Cause :** Ollama n'est pas d√©marr√©

**Solution :**
```bash
# Ouvrir un terminal et ex√©cuter :
ollama serve
```

### Probl√®me 2 : Le t√©l√©chargement reste √† 0%
**Causes possibles :**
1. Ollama n'est pas d√©marr√©
2. Probl√®me de connexion r√©seau
3. Le mod√®le est d√©j√† en cours de t√©l√©chargement dans Ollama
4. Le nom du mod√®le n'existe pas (ex: gemma3:7b n'existe pas, utilisez gemma2:9b)

**Solutions :**
```bash
# 1. V√©rifier qu'Ollama fonctionne
curl http://localhost:11434/api/tags

# 2. V√©rifier les t√©l√©chargements en cours
ollama list

# 3. Essayer de t√©l√©charger manuellement
ollama pull gemma2:2b

# 4. V√©rifier que le mod√®le existe
# Mod√®les valides : gemma2:2b, gemma2:9b, llama3.1:8b, mistral:7b, phi3:mini
```

### Probl√®me 3 : Erreur CORS dans la console
**Message :** `Access to fetch at 'http://localhost:11434' has been blocked by CORS policy`

**Solutions :**
1. Red√©marrer Ollama :
   ```bash
   # Arr√™ter Ollama (Ctrl+C dans le terminal)
   # Puis red√©marrer
   ollama serve
   ```

2. V√©rifier la version d'Ollama :
   ```bash
   ollama --version
   # Doit √™tre >= 0.1.0
   ```

### Probl√®me 4 : Le t√©l√©chargement est tr√®s lent
**C'est normal !** Les mod√®les sont volumineux :
- **Gemma 2 2B** : 1.6 GB (~5-10 minutes)
- **Phi 3 Mini** : 2.3 GB (~7-12 minutes)
- **Mistral 7B** : 4.1 GB (~12-25 minutes)
- **Llama 3.1 8B** : 4.7 GB (~15-30 minutes)
- **Gemma 2 9B** : 5.5 GB (~18-35 minutes)

La vitesse d√©pend de votre connexion internet.

### Probl√®me 5 : Erreur "Failed to download model"
**Solutions :**
1. V√©rifier l'espace disque disponible
2. V√©rifier la connexion internet
3. Essayer un mod√®le plus petit d'abord (Gemma 3 1B)
4. Red√©marrer Ollama

## üîç Diagnostic Avanc√©

### V√©rifier l'√©tat d'Ollama
```bash
# Lister les mod√®les install√©s
ollama list

# Tester la connexion
curl http://localhost:11434/api/tags

# Voir les logs d'Ollama
# (dans le terminal o√π vous avez lanc√© "ollama serve")
```

### T√©l√©charger manuellement via CLI
Si le t√©l√©chargement via l'interface ne fonctionne pas :
```bash
# T√©l√©charger directement avec Ollama
ollama pull gemma2:2b

# Une fois t√©l√©charg√©, rafra√Æchir l'interface
# Le mod√®le devrait appara√Ætre comme "Installed"
```

### Nettoyer et r√©essayer
```bash
# Supprimer un mod√®le partiellement t√©l√©charg√©
ollama rm gemma2:2b

# R√©essayer le t√©l√©chargement
ollama pull gemma2:2b
```

## üí° Conseils

### Choisir le bon mod√®le
| Mod√®le | Taille | RAM Min | Utilisation |
|--------|--------|---------|-------------|
| Gemma 2 2B | 1.6 GB | 2 GB | Tests rapides, t√¢ches simples |
| Gemma 2B | 1.4 GB | 2 GB | Mod√®le original, l√©ger et efficace |
| Phi 3 Mini | 2.3 GB | 4 GB | Compact mais capable, bon pour d√©buter |
| Mistral 7B | 4.1 GB | 8 GB | Rapide et efficace, production |
| Llama 3.1 8B | 4.7 GB | 8 GB | Excellent pour code et raisonnement |
| Gemma 2 9B | 5.5 GB | 8 GB | Meilleur √©quilibre qualit√©/taille |
| Llama 3.1 70B | 40 GB | 48 GB | Performance maximale (n√©cessite GPU) |

### Recommandations
1. **Commencez petit** : T√©l√©chargez d'abord **Gemma 2 2B** ou **Phi 3 Mini** pour tester
2. **Pour usage g√©n√©ral** : **Llama 3.1 8B** ou **Gemma 2 9B** sont excellents
3. **Pour le code** : **Llama 3.1 8B** est particuli√®rement bon
4. **Patience** : Les gros mod√®les prennent du temps
5. **Espace disque** : V√©rifiez que vous avez assez d'espace
6. **Gardez Ollama ouvert** : Ne fermez pas le terminal pendant le t√©l√©chargement

## üìù Logs Utiles

### Logs Normaux (Tout va bien)
```
Starting download for model: gemma2:2b
Download progress data: {status: "downloading", completed: 524288, total: 1677721600}
Download progress for gemma2:2b: {progress: 3.1, downloadedBytes: 524288, totalBytes: 1677721600}
Download progress data: {status: "downloading", completed: 1048576, total: 1677721600}
Download progress for gemma2:2b: {progress: 6.2, downloadedBytes: 1048576, totalBytes: 1677721600}
...
Download progress data: {status: "success"}
Model download completed successfully
Model gemma2:2b downloaded successfully
```

### Logs d'Erreur
```
Error in handleDownloadModel: Error: Ollama is not running
‚Üí Solution : D√©marrer Ollama avec "ollama serve"

Failed to download model: Failed to fetch
‚Üí Solution : V√©rifier la connexion r√©seau et qu'Ollama est d√©marr√©

Failed to download model: pull model manifest: file does not exist
‚Üí Solution : Le mod√®le n'existe pas. V√©rifier le nom (ex: gemma2:2b, pas gemma3:7b)

Failed to download model: 404 Not Found
‚Üí Solution : V√©rifier le nom du mod√®le ou essayer "ollama pull <model>"
```

## üÜò Besoin d'Aide ?

Si aucune de ces solutions ne fonctionne :

1. **V√©rifier les logs** : Ouvrez la console (F12) et copiez les messages d'erreur
2. **V√©rifier Ollama** : Assurez-vous qu'Ollama fonctionne correctement
3. **Tester manuellement** : Essayez `ollama pull gemma3:1b` dans le terminal
4. **Red√©marrer** : Red√©marrez Ollama et l'application

## ‚úÖ Checklist de D√©pannage

- [ ] Ollama est install√© (`ollama --version`)
- [ ] Ollama est en cours d'ex√©cution (`ollama serve`)
- [ ] Le port 11434 est accessible (`curl http://localhost:11434/api/tags`)
- [ ] Connexion internet active
- [ ] Espace disque suffisant (au moins 10 GB libre)
- [ ] Console du navigateur ouverte (F12) pour voir les logs
- [ ] Pas d'erreur CORS dans la console
- [ ] Pas d'autre t√©l√©chargement Ollama en cours

Si tous ces points sont verts et que √ßa ne fonctionne toujours pas, essayez de t√©l√©charger manuellement avec `ollama pull` puis rafra√Æchissez l'interface.
