# ğŸš€ Quick Reference - Gestion des ModÃ¨les Locaux

## âš¡ DÃ©marrage rapide (30 secondes)

```bash
# 1. Installer Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. DÃ©marrer Ollama
ollama serve

# 3. Dans StoryCore-Engine
Settings â†’ LLM Configuration â†’ Provider: Local â†’ TÃ©lÃ©charger un modÃ¨le â†’ Save
```

## ğŸ“Š Tableau de sÃ©lection rapide

| Votre RAM | ModÃ¨le recommandÃ© | Taille | Temps de tÃ©lÃ©chargement* |
|-----------|-------------------|--------|--------------------------|
| 2-4 GB    | Gemma 3 1B       | 1.5GB  | ~2 min                   |
| 4-8 GB    | Gemma 3 3B       | 3.5GB  | ~4 min                   |
| 8-16 GB   | Llama 3 8B       | 4.7GB  | ~5 min                   |
| 16-32 GB  | Phi 3 Medium     | 7.9GB  | ~8 min                   |
| 32+ GB + GPU | Llama 3 70B   | 40GB   | ~40 min                  |

*Avec connexion 100 Mbps

## ğŸ¯ Commandes essentielles

### Via l'interface

```
TÃ©lÃ©charger:  Clic sur "Download" dans la carte du modÃ¨le
SÃ©lectionner: Clic sur "Select" ou sur la carte
Supprimer:    Clic sur l'icÃ´ne ğŸ—‘ï¸
Filtrer:      Utiliser les boutons de famille en haut
```

### Via CLI (alternative)

```bash
# Lister les modÃ¨les disponibles
ollama list

# TÃ©lÃ©charger un modÃ¨le
ollama pull gemma3:3b

# Supprimer un modÃ¨le
ollama rm gemma3:3b

# Tester un modÃ¨le
ollama run gemma3:3b "Hello, how are you?"
```

## ğŸ” Diagnostic rapide

### ProblÃ¨me: "Ollama is not running"

```bash
# VÃ©rifier l'installation
ollama --version

# DÃ©marrer Ollama
ollama serve

# VÃ©rifier le port
curl http://localhost:11434/api/tags
```

### ProblÃ¨me: TÃ©lÃ©chargement lent

```bash
# VÃ©rifier la connexion
ping ollama.ai

# TÃ©lÃ©charger via CLI (plus rapide parfois)
ollama pull gemma3:3b

# VÃ©rifier l'espace disque
df -h
```

### ProblÃ¨me: ModÃ¨le lent

```bash
# VÃ©rifier la RAM utilisÃ©e
top

# Passer Ã  un modÃ¨le plus petit
# Gemma 3 7B â†’ Gemma 3 3B â†’ Gemma 3 1B
```

## ğŸ“¦ Catalogue rapide

### Gemma 3 (Google)
```
1B:  Rapide, lÃ©ger, tÃ¢ches basiques
3B:  Ã‰quilibrÃ©, usage gÃ©nÃ©ral
7B:  Puissant, tÃ¢ches complexes
```

### Llama 3 (Meta)
```
8B:  Excellent, usage gÃ©nÃ©ral
70B: Top qualitÃ©, nÃ©cessite GPU
```

### Mistral (Mistral AI)
```
7B:  Rapide, efficace, production
```

### Phi 3 (Microsoft)
```
Mini:   Compact, surprenant
Medium: QualitÃ© excellente
```

### Qwen 2 (Alibaba)
```
7B: Multilingue, international
```

## ğŸ¨ Badges et indicateurs

```
âš¡ Recommended  â†’ RecommandÃ© pour votre systÃ¨me
âœ“ Installed    â†’ DÃ©jÃ  tÃ©lÃ©chargÃ©
ğŸ’¾ Size        â†’ Taille du modÃ¨le
ğŸ–¥ï¸ RAM         â†’ RAM requise
âš¡ GPU         â†’ GPU nÃ©cessaire
ğŸ—‘ï¸             â†’ Supprimer
```

## ğŸ’¡ Astuces pro

### 1. Commencer petit
```
Toujours tester avec Gemma 3 1B d'abord
Puis augmenter si nÃ©cessaire
```

### 2. Surveiller la RAM
```
Garder 20-30% de RAM libre
Fermer les autres applications
```

### 3. Utiliser les filtres
```
"Installed Only" pour voir rapidement vos modÃ¨les
Filtres de famille pour explorer
```

### 4. TÃ©lÃ©charger la nuit
```
Les gros modÃ¨les (70B) prennent du temps
Lancer le tÃ©lÃ©chargement avant de dormir
```

### 5. Tester avant de sauvegarder
```
Utiliser "Test Connection" avant "Save Settings"
VÃ©rifier que le modÃ¨le rÃ©pond bien
```

## ğŸ”— Liens utiles

```
Site Ollama:        https://ollama.ai
Documentation:      https://github.com/ollama/ollama
ModÃ¨les disponibles: https://ollama.ai/library
Support:            https://github.com/ollama/ollama/issues
```

## ğŸ“± Raccourcis clavier

```
Ctrl/Cmd + S    â†’ Sauvegarder les paramÃ¨tres
Esc             â†’ Fermer les dialogues
Tab             â†’ Naviguer entre les champs
Enter           â†’ Confirmer les actions
```

## ğŸ¯ Checklist de dÃ©marrage

```
â˜ Ollama installÃ©
â˜ Ollama en cours d'exÃ©cution (ollama serve)
â˜ Espace disque suffisant (vÃ©rifier avec df -h)
â˜ RAM disponible (vÃ©rifier avec top/htop)
â˜ Connexion internet stable
â˜ Settings â†’ LLM Configuration ouvert
â˜ Provider "Local" sÃ©lectionnÃ©
â˜ ModÃ¨le tÃ©lÃ©chargÃ©
â˜ ModÃ¨le sÃ©lectionnÃ©
â˜ Configuration sauvegardÃ©e
â˜ Test de gÃ©nÃ©ration rÃ©ussi
```

## ğŸš¨ Erreurs courantes

### "No models found"
```
Solution: TÃ©lÃ©charger au moins un modÃ¨le
```

### "Connection failed"
```
Solution: VÃ©rifier qu'Ollama est dÃ©marrÃ© (ollama serve)
```

### "Out of memory"
```
Solution: Choisir un modÃ¨le plus petit ou fermer d'autres apps
```

### "Download stuck at X%"
```
Solution: Annuler et rÃ©essayer, ou utiliser CLI (ollama pull)
```

### "Model not responding"
```
Solution: RedÃ©marrer Ollama (killall ollama && ollama serve)
```

## ğŸ“Š Comparaison rapide

### Vitesse vs QualitÃ©

```
Rapide:  Gemma 3 1B, Phi 3 Mini
Moyen:   Gemma 3 3B, Mistral 7B
Lent:    Llama 3 8B, Gemma 3 7B
TrÃ¨s lent: Llama 3 70B, Phi 3 Medium
```

### Taille vs Performance

```
Petit (1-3B):   Bon pour tÃ¢ches simples
Moyen (7-8B):   Excellent pour usage gÃ©nÃ©ral
Grand (70B+):   Meilleur qualitÃ©, nÃ©cessite ressources
```

### SpÃ©cialisation

```
GÃ©nÃ©ral:     Gemma 3, Llama 3
Code:        Mistral 7B, Llama 3 8B
Multilingue: Qwen 2 7B
Compact:     Phi 3 Mini, Gemma 3 1B
```

## ğŸ“ Progression recommandÃ©e

### DÃ©butant
```
1. Installer Ollama
2. TÃ©lÃ©charger Gemma 3 1B
3. Tester avec des prompts simples
4. Se familiariser avec l'interface
```

### IntermÃ©diaire
```
1. Essayer Gemma 3 3B ou Llama 3 8B
2. Comparer les performances
3. Ajuster les paramÃ¨tres (tempÃ©rature, etc.)
4. Utiliser dans les wizards
```

### AvancÃ©
```
1. Tester plusieurs modÃ¨les
2. Optimiser pour votre cas d'usage
3. Utiliser les modÃ¨les spÃ©cialisÃ©s
4. IntÃ©grer dans des workflows personnalisÃ©s
```

## ğŸ’¾ Gestion de l'espace disque

### VÃ©rifier l'espace
```bash
# Linux/Mac
df -h ~/.ollama

# Windows
dir %USERPROFILE%\.ollama
```

### Nettoyer
```bash
# Supprimer les modÃ¨les non utilisÃ©s
ollama rm <model-name>

# Lister pour voir ce qui prend de la place
ollama list
```

### Optimiser
```
- Garder seulement 2-3 modÃ¨les actifs
- Supprimer les anciens modÃ¨les
- Utiliser des modÃ¨les plus petits si possible
```

## ğŸ”„ Mise Ã  jour

### Mettre Ã  jour Ollama
```bash
# Mac/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Ou via package manager
brew upgrade ollama  # Mac
```

### Mettre Ã  jour un modÃ¨le
```bash
# Re-tÃ©lÃ©charger la derniÃ¨re version
ollama pull gemma3:3b
```

---

**Gardez cette rÃ©fÃ©rence Ã  portÃ©e de main pour un accÃ¨s rapide aux informations essentielles!**
