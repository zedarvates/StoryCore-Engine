# Correction - Boutons IA D√©sactiv√©s

## üêõ Probl√®me

Les boutons d'assistance IA dans le wizard World Building restaient d√©sactiv√©s m√™me quand le LLM √©tait correctement configur√©:

- ‚ùå Step 1: "Suggest Name" d√©sactiv√©
- ‚ùå Step 2: "Generate Rules" d√©sactiv√©  
- ‚ùå Step 3: "Generate Locations" d√©sactiv√©
- ‚ùå Step 4: "Generate Elements" d√©sactiv√©

## üîç Cause Racine

Le hook `useServiceStatus()` cherchait la configuration LLM dans la mauvaise cl√© de localStorage:

**Avant (INCORRECT)**:
```typescript
const llmConfig = localStorage.getItem('llm-config'); // ‚ùå Cl√© inexistante
```

**R√©alit√©**:
La configuration LLM est stock√©e dans `'storycore-settings'` avec une structure chiffr√©e:
```typescript
{
  llm: {
    config: { provider, model, endpoint, ... },
    encryptedApiKey: "...",
    lastValidated: "..."
  },
  comfyui: { ... },
  version: "1.0"
}
```

## ‚úÖ Solution Appliqu√©e

**Fichier**: `creative-studio-ui/src/components/ui/service-warning.tsx`

### Correction du Hook `useServiceStatus`

```typescript
export function useServiceStatus() {
  const [llmConfigured, setLLMConfigured] = React.useState(false);
  const [comfyUIConfigured, setComfyUIConfigured] = React.useState(false);

  React.useEffect(() => {
    // ‚úÖ Lire depuis 'storycore-settings'
    try {
      const storedSettings = localStorage.getItem('storycore-settings');
      if (storedSettings) {
        const settings = JSON.parse(storedSettings);
        
        // V√©rifier si LLM est configur√©
        const hasLLMConfig = settings.llm?.config?.provider;
        const hasApiKey = settings.llm?.encryptedApiKey;
        const isOllama = settings.llm?.config?.provider === 'ollama' || 
                        settings.llm?.config?.provider === 'local';
        
        // LLM configur√© si: provider + (apiKey OU Ollama)
        setLLMConfigured(!!(hasLLMConfig && (hasApiKey || isOllama)));
      } else {
        setLLMConfigured(false);
      }
    } catch (error) {
      console.error('Failed to check LLM config:', error);
      setLLMConfigured(false);
    }

    // V√©rifier ComfyUI (avec fallback vers ancien stockage)
    try {
      const storedSettings = localStorage.getItem('storycore-settings');
      if (storedSettings) {
        const settings = JSON.parse(storedSettings);
        setComfyUIConfigured(!!(settings.comfyui?.config?.serverUrl));
      } else {
        // Fallback: ancien syst√®me de stockage
        const comfyUIServers = localStorage.getItem('comfyui-servers');
        if (comfyUIServers) {
          const servers = JSON.parse(comfyUIServers);
          setComfyUIConfigured(!!(servers.servers && servers.servers.length > 0));
        } else {
          setComfyUIConfigured(false);
        }
      }
    } catch (error) {
      console.error('Failed to check ComfyUI config:', error);
      setComfyUIConfigured(false);
    }
  }, []);

  return {
    llmConfigured,
    comfyUIConfigured,
    anyConfigured: llmConfigured || comfyUIConfigured,
    allConfigured: llmConfigured && comfyUIConfigured,
  };
}
```

## üéØ Logique de D√©tection

### LLM Configur√© Si:

1. **Provider existe**: `settings.llm?.config?.provider` est d√©fini
2. **ET** l'une des conditions suivantes:
   - **API Key chiffr√©e existe**: `settings.llm?.encryptedApiKey` est d√©fini
   - **OU Provider est Ollama/Local**: Pas besoin d'API key

### Providers Support√©s:

- ‚úÖ **OpenAI**: N√©cessite `encryptedApiKey`
- ‚úÖ **Anthropic**: N√©cessite `encryptedApiKey`
- ‚úÖ **Ollama**: Pas d'API key n√©cessaire (provider = 'ollama' ou 'local')
- ‚úÖ **Autres**: N√©cessite `encryptedApiKey`

## üìä R√©sultat Attendu

Apr√®s cette correction:

### Avec LLM Configur√© (Ollama)
```
‚úÖ Step 1: "Suggest Name" ACTIV√â
‚úÖ Step 2: "Generate Rules" ACTIV√â
‚úÖ Step 3: "Generate Locations" ACTIV√â
‚úÖ Step 4: "Generate Elements" ACTIV√â
‚ùå ServiceWarning CACH√â
```

### Sans LLM Configur√©
```
‚ùå Step 1: "Suggest Name" D√âSACTIV√â
‚ùå Step 2: "Generate Rules" D√âSACTIV√â
‚ùå Step 3: "Generate Locations" D√âSACTIV√â
‚ùå Step 4: "Generate Elements" D√âSACTIV√â
‚ö†Ô∏è ServiceWarning AFFICH√â avec bouton "Configure LLM"
```

## üß™ Comment Tester

### Test 1: Avec Ollama Configur√©

1. Ouvrir Settings > LLM Configuration
2. Configurer Ollama (localhost:11434)
3. S√©lectionner un mod√®le (ex: gemma2:2b)
4. Sauvegarder
5. Ouvrir le wizard World Building
6. **V√©rifier**: Tous les boutons "Generate" sont activ√©s
7. **V√©rifier**: Pas de ServiceWarning affich√©

### Test 2: Sans LLM Configur√©

1. Ouvrir Settings > LLM Configuration
2. Supprimer la configuration (ou ne rien configurer)
3. Ouvrir le wizard World Building
4. **V√©rifier**: Tous les boutons "Generate" sont d√©sactiv√©s
5. **V√©rifier**: ServiceWarning affich√© avec message
6. Cliquer sur "Configure LLM"
7. **V√©rifier**: Modal de configuration s'ouvre

### Test 3: Avec OpenAI/Anthropic

1. Ouvrir Settings > LLM Configuration
2. Configurer OpenAI ou Anthropic avec API key
3. Sauvegarder
4. Ouvrir le wizard World Building
5. **V√©rifier**: Tous les boutons "Generate" sont activ√©s

## üîß Debug

Si les boutons restent d√©sactiv√©s:

### V√©rifier le localStorage

Ouvrir la console du navigateur (F12) et ex√©cuter:

```javascript
// V√©rifier le contenu de storycore-settings
const settings = JSON.parse(localStorage.getItem('storycore-settings'));
console.log('Settings:', settings);

// V√©rifier la configuration LLM
console.log('LLM Config:', settings?.llm?.config);
console.log('Has API Key:', !!settings?.llm?.encryptedApiKey);
console.log('Provider:', settings?.llm?.config?.provider);

// V√©rifier la d√©tection
const hasLLMConfig = settings?.llm?.config?.provider;
const hasApiKey = settings?.llm?.encryptedApiKey;
const isOllama = settings?.llm?.config?.provider === 'ollama' || 
                settings?.llm?.config?.provider === 'local';
console.log('LLM Configured:', !!(hasLLMConfig && (hasApiKey || isOllama)));
```

### R√©sultats Attendus

**Avec Ollama**:
```javascript
LLM Config: { provider: 'ollama', endpoint: 'http://localhost:11434', model: 'gemma2:2b' }
Has API Key: false
Provider: ollama
LLM Configured: true ‚úÖ
```

**Avec OpenAI**:
```javascript
LLM Config: { provider: 'openai', model: 'gpt-4' }
Has API Key: true
Provider: openai
LLM Configured: true ‚úÖ
```

**Sans Configuration**:
```javascript
LLM Config: undefined
Has API Key: false
Provider: undefined
LLM Configured: false ‚ùå
```

## üìù Notes Importantes

1. **Cache du navigateur**: Apr√®s la correction, faire un hard refresh (Ctrl+F5)
2. **R√©activit√©**: Le hook v√©rifie la configuration au montage du composant
3. **Pas de r√©activit√© automatique**: Si vous configurez le LLM pendant que le wizard est ouvert, vous devez fermer et rouvrir le wizard
4. **S√©curit√©**: L'API key est toujours chiffr√©e dans le localStorage

## üöÄ Prochaines Am√©liorations Possibles

1. **R√©activit√© en temps r√©el**: √âcouter les changements de localStorage
2. **Indicateur visuel**: Badge "LLM Ready" dans l'interface
3. **Test de connexion**: V√©rifier que le LLM r√©pond avant d'activer les boutons
4. **Cache du statut**: √âviter de parser le JSON √† chaque render

---

**Statut**: ‚úÖ Corrig√© - Les boutons s'activent maintenant correctement  
**Date**: 2026-01-20  
**Impact**: Tous les boutons d'assistance IA fonctionnent quand le LLM est configur√©
