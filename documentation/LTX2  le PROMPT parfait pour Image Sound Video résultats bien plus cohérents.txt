Donc là, il y a plein de mouvements de caméra que j'ai ajouté, j'ai changé aussi d'image et j'obtiens ce résultat. J'adore jouer de la batterie. LTX2 est un monstre de modèle vidéo. On peut importer des images, des vidéos et du son et faire en sorte que tout ça soit parfaitement cohérent. Dans cette vidéo, je vous donne des conseils pour bien prompter lorsqu'il s'agit justement de mettre en cohérence du son et des image. C'est hyper intéressant. Alors, on va commencer avec cette image là. Voilà, toute simple. Et j'aimerais évidemment la faire parler. Je vais utiliser ça comme fichier son. Voici mon premier essai et on va essayer de voir pourquoi ça a pas fonctionné. Donc vous voyez, c'est totalement figé. On a juste la caméra qui avance un peu et on n pas du tout de synchronisation labiale. Alors voici le workflow. Je vous mettrai le lien pour le récupérer dans la description. Ici j'ai indiqué et c'est hyper important lip sync. Si vous voyez que vous n'avez pas de mouvement, vous pourrez rajouter ça. Malgré le fait que j'ai une description assez précise de la personne et que je dis qu'elle parle, et bien il n'y a aucun mouvement. Ça fonctionne pas. Si on réécoute le son, voyez, il n'y a pas de blanc au début, ça attaque direct. Je vous remontre. OK, donc ça ça peut figer l'image. Si on ajoute du blanc au début, ça fonctionne. Alors, vous entendez ? J'ai rajouté du bruit. Même je tapote sur mon clavier. On l'entend un petit peu. Donc voilà, si vous voyez que ça fonctionne pas, vérifiez bien ce qu'il y a écrit dans le prompt. Bien sûr, l'ipsique, ça peut aider. Vous indiquez bien ce qu'elle fait et vous faites une petite description. C'est pas nécessaire toujours, mais ça peut aider d'avoir la description de la personne. Et le fait d'ajouter un peu de silence ou un léger bruit avant que ça parle, ça peut aider aussi. Voici un autre exemple qui a bien fonctionné avec un autre fichier son. Au début, j'ai laissé du blanc. Le prompt, c'est exactement le même. C'est juste le fichier son qui a changé avec ce fameux blanc au début. Donc c'est important si vous voyez que ça fiche de bienajouter. Voici un exemple avec peu de descriptions dans le prompt. Donc ça fonctionne aussi. Le prompte là, c'était juste Young Woman is speaking. J'ai même pas rajouté lipsink, c'était pas nécessaire. Voyons voir d'autres choses qui peuvent bloquer l'animation. Par exemple, si vous avez une image qui ne correspond pas du tout à la voix, si j'utilise cette image d'un vieux monsieur avec le même son, et bien ça va pas du tout fonctionner. Le modèle ne voit pas la concordance entre le son et l'image et du coup ça marche pas. Voilà, même si j'indique, je vais vous montrer ici que c'est un vieil homme qui parle et bien ça fonctionne pas. L'animation peut aussi être figée et ne pas partir pour d'autres raisons. Par exemple ça. Voilà, là c'est figé. Pourtant j'ai le bon fichier son. Et bien dans ce cas, si j'ajoute lip sync avec exactement le même fichier son et bien je vais obtenir un résultat qui est satisfaisant cette fois-ci. Donc lipsink, ça peut aider si vous voyez que ça bloque. En plus d'avoir ajouté un blanc au début. Là je l'ai pas ajouté, c'était directement dans le fichier son. Je vais vous montrer un exemple qui a très très bien fonctionné avec cette vieille personne. Qu'est-ce que j'ai indiqué ici comme prompte ? Et bien exactement la même chose, sauf que j'ai précisé qu'il souriait et c'est parfaitement cohérent avec le son. Et justement ça c'est hyper important si vous mettez un fichier son d'une personne qui pleure ou qui est triste avec une description contraire dans le prompt, ça ne va pas fonctionner. aussi par exemple ça. L'animation commence bien mais elle s'arrête au bout d'un moment parce qu'il y a une incohérence entre le prompt et le son. Je vais vous montrer ce que j'ai indiqué dans le prompt. J'ai laissé le prompt du vieux monsieur. Donc j'ai dit que c'était un vieil homme qui souriait et qui parlait. Et voyez qu'au bout d'un moment euh le modèle s'est aperçu que ça pouvait pas fonctionner. Un autre cas qui ne fonctionne pas, c'est celui-ci. Ça commence un petit peu au début et puis ça s'arrête assez vite. Pourquoi ? Je vais vous montrer ici. Le gros problème ici, c'est la séquence des événements. Elle parle au début, ensuite elle a l'air triste et cetera. C'est pas très cohérent. Et en plus, il y a des éléments de décor qui ne figurent pas dans l'image qui a été recadrée puisque ce prompt a été créé à partir de la description de l'image non recadrée et du coup ça colle pas trop avec l'image fournie au modèle. Il est important donc que les événements s'enchaînent de manière logique. Voici un exemple qui a bien fonctionné. Ça marche super bien. Et qu'est-ce que j'ai indiqué dans le prompt ? Je montre que c'est une femme adulte qui est triste. C'est parfaitement cohérent avec la bande son. Je dis qu'elle parle. Pour être sûr, j'ajoute Lipsync et ensuite seulement je fais une description du décor et j'ai supprimé les éléments qui n'étaient pas visibles. Il est tout à fait possible, si vous avez un blanc entre deux phrases, de réaliser une action. Par exemple, j'aimerais que la personne qu'on a vu tout à l'heure enlève ses lunettes et continue à parler. Donc voici un résultat qui a bien fonctionné. Qu'est-ce que j'ai indiqué dans le prompt ? Après avoir fait la description de la personne ici, j'écris carrément ce qu'elle dit. Ça peut aider ça aussi. Donc elle dit tout ça ensuite. Donc j'utilise le mot zen. Elle enlève ses lunettes. OK, donc c'est une autre action. Pendant ce temps-là, j'ai un blanc dans mon audio. Et ensuite elle continue, elle dit la suite en fait. Voilà, j'ai rajouté lipsing pour être sûr. Et donc on obtient ça. Je vous remontre. Ça marche très bien. On va pouvoir vraiment faire des actions intégrées au Lip Syinking. Ce modèle est tellement balaise qu'il peut synchroniser les mouvements des lèvres avec de la voix, on l'a vu, mais on va pouvoir aussi synchroniser des mouvements avec le son. Par exemple, ici, j'aimerais que la personne parle, mais aussi qu'elle se mette à jouer de la batterie d'une manière crédible. Vous avez vu l'image ? Voici le son. J'adore jouer de la batterie. OK, voyons voir le résultat avec le mélange de tout ça. J'adore jouer de la batterie. Qu'est-ce que j'ai mis dans le prompt pour obtenir tout ça ? D'abord, une description de tout ce que l'on voit dans l'image. Ça va jusque là. Ensuite, j'indique que la personne dit d'une manière calme : &quot;J'adore jouer de la batterie.&quot; Et enfin, quelque chose d'hyper important pour obtenir un mouvement qui soit crédible. Je décris ce qu'il va faire. Il hoche la tête, il baisse les yeux vers le Charlestone, il marque doucement le tempo d'un mouvement contrôlé du poignet tandis que son pied se pose sur la de grosse caisse et le résultat est tout à fait crédible. Donc c'est très important si vous souhaitez faire une synchronisation aussi avec le son, ben d'expliquer ce qu'il se passe concrètement. Voici un prompt qui n'a pas du tout fonctionné. C'est exactement le même début, sauf que au lieu de décrire ce qu'il fait exactement là, j'indique qu'ensuite après avoir parlé, donc il se met à jouer de la batterie et le résultat c'est ça. J'adore jouer de la batterie. L'image n'a même pas été prise en compte. Alors, on va pouvoir aller beaucoup plus loin si on ajoute en plus de la description de la personne qui joue la description des mouvements de caméra. Donc là, il y a plein de mouvements de caméra que j'ai ajouté, j'ai changé aussi d'image et j'obtiens ce résultat. J'adore jouer de la batterie. Il est donc hyper important d'avoir une bonne description de ce que l'on voit dans l'image, ainsi qu'une succession logique d'événements et surtout très important de bien décrire les mouvements correspondant à un instrument que l'on joue, par exemple. J'adore jouer de la batterie. Donc on va voir maintenant quelque chose encore plus intéressant, c'est comment on peut animer deux personnes à la fois et synchroniser leur voix. J'avais déjà fait ça dans une vidéo dans laquelle j'avais présenté Van Animate et le son c'est ça. Et bien voilà, c'est parti pour ce nouveau stream. Dis-moi François, qu'est-ce qu'on va faire aujourd'hui ? Et bien mon très cher Robert, aujourd'hui nous allons parler de la chourûe de Garni. Ah ! Et l'image c'est celle-ci. Donc deux streamers dont un qui est un ogre. Voici un exemple qui n'a pas fonctionné et on va essayer de voir pourquoi. Et bien voilà, c'est parti pour ce nouveau stream. Dis-moi François, qu'est-ce qu'on va faire aujourd'hui ? Donc là, on voit bien que les deux parlent en même temps. Voici le prompt. Je fais une description du lieu, je fais une description de la première personne et je dis tout simplement que le jeune homme parle. Bien, on s'aperçoit que du coup les deux parlent en même temps. Il va falloir être beaucoup plus précis que ça quand vous avez deux personnages. Alors pour bien comprendre comment fonctionner le prompt, j'ai supprimé la bande son et je me suis uniquement concentré sur le prompt. Voici un autre exemple. Bonjour mon cher François, comment ça va aujourd'hui ? Bonjour mon cher Robert, ça va hyper bien merci. J'ai indiqué dans le prompt la même chose. Je fais une mise en contexte. Je fais une description des deux personnages et j'écris ensuite que le jeune homme avec le oud gris regarde l'ogre et dit &quot;Bonjour mon cher François, comment ça va aujourd'hui ?&quot; L'ogre répond en regardant le jeune homme : &quot;Bonjour mon cher Robert, ça va hyper bien merci.&quot; Après, je fais une description du lieu. Donc je vous remontre ce que ça donne. Bonjour mon cher François, comment ça va aujourd'hui ? Bonjour mon cher Robert, ça va hyper bien merci. Donc ça fonctionne pas mal mais c'est pas encore top. En faisant ça, j'ai compris qu'il était hyper important de décrire ou d'expliquer quel est l'interlocuteur évidemment qui parle. Et si on ajoute une petite description de la personne, ça aide Lia à comprendre qui va parler. Bonjour mon cher François, comment ça va aujourd'hui ? Bonjour mon cher Robert, ça va hyper bien merci. Donc là, ça a bien marché même si à la fin il dit quelque chose un peu fort. Donc là, j'ai simplifié, je fais pas de description de la scène. J'indique la personne A qui est le jeune homme avec le gris regarde l'ogre et dit bonjour mon cher François et cetera. Que la personne B c'est l'ogre le jeune homme et dit bonjour. Et là ça commence à fonctionner pas mal du tout. Je vous remontre. Bonjour mon cher François, comment ça va aujourd'hui ? Bonjour mon cher Robert, ça va hyper bien merci. Alors, puisque ça a bien marché, je me suis dit tiens, est-ce qu'on pourrait pas faire en sorte qu'il se disent bonjour en se cognant les points ? Ça donne ce résultat. Bonjour mon cher François, comment ça va aujourd'hui ? Bonjour mon cher Robert, ça va hyper bien merci. Je trouve que ça marche vachement bien. Donc là, ce que j'ai indiqué, c'est tout simplement dans le prompt que après avoir parlé, donc là ils font leur discours, ils font un fist bump. Donc voici un exemple cette fois-ci enfin avec mon fichier son en plus de l'image. Alors l'image est un petit peu dégradée car j'avais fait une erreur dans le workflow et ça a été corrigé. Et bien voilà, c'est parti pour ce nouveau stream. Dis-moi François, qu'est-ce qu'on va faire aujourd'hui ? Et bien mon très cher Robert, aujourd'hui nous allons parler de la choue de Garni. Ah donc là ça a bien fonctionné et je vais vous montrer ce que j'ai écrit. Donc voilà, j'ai un prompte assez détaillé dans lequel j'explique qui est la personne a. C'est le jeune homme avec le gris qui regarde l'ogre et qui dit &quot;Et bien voilà, c'est parti pour un nouveau stream. Dis-moi François, qu'est-ce qu'on va faire aujourd'hui ?&quot; La personne B, c'est l'ogre qui regarde le jeune homme et qui répond et bien mon très cher Robert, j'ai ôé le thé sinon ça dit &quot;Robert, aujourd'hui nous allons parler de la choucroûe garnie.&quot; Ensuite, ils font un fb et voilà. Et là, ça fonctionne très bien. Donc, on peut effectivement faire parler plusieurs personnages. Il suffit juste de respecter l'ordre de passage de chacun des dialogues et surtout de bien décrire chaque intervenant. Avant que je vous parle du workflow, voici un petit récapitulatif. Avoir un peu de silence au début de la bande son. Parfois, le mot lipync peut aider. La description de l'image est importante. Il doit y avoir une cohérence entre le son et l'image. Avoir une cohérence entre le sujet, ses émotions avec l'image, le son et le prompt. S'il y a des actions, celles-ci doivent s'enchaîner en étant conforme au fichier son. Si on doit synchroniser des actions avec du son, il faut décrire ces actions. Bien décrire chaque intervenant dans le cas d'un dialogue à plusieurs. Voici le workflow. Je l'ai fait en partant du workflow de base sur lequel j'ai rajouté la possibilité d'ajouter du son. Je l'ai complètement déstructuré car j'aime pas trop en fait le ce système de subgraphe. Donc j'ai tout sorti et je l'ai reconstruit en ajoutant la possibilité de mettre notre propre audio ainsi que notre propre image de départ. Alors ça fonctionne aussi si on en met une au début, une à la fin. Si ça vous intéresse, je vous montrerai comment faire. Mais pour l'instant, on va se concentrer sur ce workflow. Donc ici, vous allez mettre votre image. Ensuite, là, vous allez indiquer la taille que vous souhaitez. Donc, ne soyez pas trop gourmand. Là, vous allez indiquer le frame rate que 50, c'est un petit peu trop. Là, vous allez indiquer la durée du son. Donc, en fait, ce que j'ai mis ici, c'est la possibilité de d'entendre une preview. Donc, en fonction du début. Donc, ça c'est le début. Par exemple, si je souhaite que ça commence à 2 secondes, je vais mettre ici deux. Je fais ensuite un clic sur ce nœud. Je clique ensuite sur le bouton bleu pour avoir une preview du son. Le son de base fait 8 secondes. Je dis que ça commence à de donc forcément il nous reste plus que 6 secondes. Mais ici, j'ai indiqué 8. Donc la vidéo fera 8 secondes malgré le fait que le son n'est que sur 6. Donc faites bien attention à ça. Alors bien sûr, on pourrait faire en sorte dans le workflow d'avoir ici une adquation entre la durée de l'audio et la durée de la vidéo. Je l'ai pas fait mais c'est très facile à mettre en place. En attendant, faites correspondre la durée avec celle de l'audio. Après pour le reste et bien vous avez juste à faire attention à bien charger ici le modèle qui va là. Ensuite le laura ici ainsi que l'upscaler. Et vous avez ici la possibilité de rajouter des lauras pour le stage 2, c'est-à-dire pour l'étape de l'agrandissement et le laura pour le stage 1. Si vous souhaitez ne pas faire de stage 2, c'est-à-dire de pas faire d'agrandissement, vous pouvez bypasser ça, tout ce groupe et faire fonctionner celui-ci. Pour le reste, vous avez ce groupe qui est important qui nous permet d'isoler la voix à partir de ce nœud ici. Donc ça, ça nous permet d'avoir l'audio qui arrive ici. On sort que le vocal si on le souhaite. Donc dans l'exemple de moi en train de jouer de la batterie et bien j'ai été obligé de le désactiver si je souhaite que Lia entende l'instrument. OK ? Donc si vous voulez le remettre et bien il suffit tout simplement de désactiver ce nœud ici custom audio et vous le branchez là comme ça. Donc là il y a que la voie ce qui peut aider hein parfois lorsque l'on souhaite faire de la synchronisation juste avec la voie dans le workflow que vous pourrez récupérer ce sera connecté comme ça. Donc si vous voulez avoir aussi l'instrument, il vous faudra mettre ici un get custom audio qui n'est pas présent dans le workflow. En dessous, vous avez ce nœud là qui nous permet de calculer à partir du temps que l'on a mis une séquence qui est un multiple de 8 plus 1 pour le nombre de frames. Alors, ce workflow n'est pas optimisé pour les petites configurations car j'ai pas eu le temps de m'y pencher sérieusement. Il vous faut au moins avoir 64 Go de RAM et entre 16 et 24 Go de VAM. Donc comme je vous le disais dans les précédentes vidéos, ce que je fais c'est que je peux partager mes workflow sur Floyo. Ce qui vous permet vous si vous voulez tester le workflow, ben le faire directement sur le site. Vous pouvez aussi récupérer le workflow à partir de là. Donc j'ai un workflow qui est juste du son pour la vidéo. Donc il suffit juste de mettre votre son et ça va vous sortir une vidéo en rapport avec le son. Et j'ai fait un autre workflow qui est celui que je vous ai présenté qui est celui-ci qui vous permet d'importer à la fois une image et d'avoir le son et cetera. Quand vous aurez le lien, vous pourrez ouvrir le workflow. Vous allez l'avoir là. Si vous voulez le tester, ben mettez votre image et votre son dans les nœuds correspondants. Et si vous voulez récupérer le workflow, c'est tout à fait possible. Je vous remercie d'avoir suivi cette vidéo. Si vous avez des questions, n'hésitez pas à le faire dans les commentaires. Si vous souhaitez soutenir cette chaîne, vous pouvez cliquer sur j'aime, c'est hyper important pour le réfancement. Et si vous n'êtes pas abonné et que vous souhaitez le faire, vous pouvez cliquer sur abonnez-vous. N'oubliez pas la petite clochette pour être averti des prochains cours ou des prochains tutos.KSamplerSelect
GetNode
ManualSigmas
RandomNoise
LatentUpscaleModelLoader
ltx-2-spatial-upscaler-x2-1.0.safetensors
LoadAudio
Note
Label (rgthree)
PrimitiveFloat
LoadImage
CheckpointLoaderSimple
Ltx-2\ltx-2-19b-dev.safetensors
LTXVAudioVAELoader
Ltx-2\ltx-2-19b-dev.safetensors
SolidMask
SaveVideo
SetNode
PrimitiveInt
TrimAudioDuration
ResizeImageMaskNode
CLIPTextEncode
Reroute
EmptyImage
LoraLoaderModelOnly
Ltx2\ltx-2-19b-ic-lora-detailer.safetensors
Ltx2\ltx-2-19b-distilled-lora-384.safetensors
LTXVAudioVAEEncode
LTXVPreprocess
PreviewAudio
ImageScaleBy
SetLatentNoiseMask
LTXVConditioning
GetImageSize
CFGGuider
EmptyLTXVLatentVideo
LTXVImgToVideoInplace
LTXVConcatAVLatent
LTXVScheduler
SamplerCustomAdvanced
LTXVSeparateAVLatent
VAEDecode
VAEDecodeTiled
LTXVAudioVAEDecode
LTXVCropGuides
CreateVideo
LTXVLatentUpsampler

ComfyUI-MelBandRoFormer
MelBandRoFormerModelLoader
MelBandRoformer_fp16.safetensors
MelBandRoFormerSampler

ComfyUI_crdong
INTConstant

ComfyUI-KJNodes
INTConstant

ComfyUI-LTXVideo
LTXVGemmaCLIPModelLoader
gemma_3_12B_it.safetensors
Ltx-2\ltx-2-19b-dev.safetensors

was-node-suite-comfyui
Text Multiline

ComfyUI_Fill-Nodes
FL_IntToFloat

ComfyUI_essentials
SimpleMath+

ComfyUI-Easy-Use
easy showAnything