# Message d'Avertissement Ollama dans les ChatBox

## Vue d'ensemble

Les composants ChatBox affichent maintenant un message d'avertissement si Ollama n'est pas d√©tect√©, invitant l'utilisateur √† l'installer ou le d√©marrer.

## Composants Modifi√©s

### 1. ChatBox.tsx (√âditeur Principal)
**Fichier**: `creative-studio-ui/src/components/ChatBox.tsx`

**Modifications**:
- ‚úÖ Import de `checkOllamaStatus` depuis `@/services/ollamaConfig`
- ‚úÖ Import des ic√¥nes `AlertCircle` et `Download` de lucide-react
- ‚úÖ Ajout d'un √©tat `isOllamaAvailable` (boolean | null)
- ‚úÖ V√©rification du statut Ollama au montage du composant
- ‚úÖ Affichage d'une banni√®re d'avertissement si Ollama n'est pas disponible

**Banni√®re d'avertissement**:
```tsx
{isOllamaAvailable === false && (
  <div className="rounded-lg border-2 border-orange-200 bg-orange-50 p-4">
    <div className="flex items-start gap-3">
      <AlertCircle className="w-5 h-5 text-orange-600" />
      <div>
        <h3>Ollama n'est pas d√©tect√©</h3>
        <p>L'assistant AI n√©cessite Ollama...</p>
        <a href="https://ollama.com/download/windows">
          T√©l√©charger Ollama
        </a>
        <button onClick={checkAgain}>
          V√©rifier √† nouveau
        </button>
      </div>
    </div>
  </div>
)}
```

### 2. LandingChatBox.tsx (Page d'Accueil)
**Fichier**: `creative-studio-ui/src/components/launcher/LandingChatBox.tsx`

**Modifications**:
- ‚úÖ Import de `checkOllamaStatus` depuis `@/services/ollamaConfig`
- ‚úÖ Import des ic√¥nes `AlertCircle` et `Download` de lucide-react
- ‚úÖ Ajout d'un √©tat `isOllamaAvailable` (boolean | null)
- ‚úÖ V√©rification du statut Ollama au montage du composant
- ‚úÖ Affichage d'une banni√®re d'avertissement compacte (th√®me sombre)

**Banni√®re d'avertissement** (version compacte pour th√®me sombre):
```tsx
{isOllamaAvailable === false && (
  <div className="rounded-lg border-2 border-orange-500/50 bg-orange-900/20 p-3">
    <div className="flex items-start gap-2">
      <AlertCircle className="w-4 h-4 text-orange-400" />
      <div>
        <h4>Ollama n'est pas d√©tect√©</h4>
        <p>L'assistant AI n√©cessite Ollama...</p>
        <a href="https://ollama.com/download/windows">
          T√©l√©charger
        </a>
        <button onClick={checkAgain}>
          V√©rifier
        </button>
      </div>
    </div>
  </div>
)}
```

## Fonctionnalit√©s de la Banni√®re

### 1. D√©tection Automatique
- ‚úÖ V√©rification au montage du composant
- ‚úÖ √âtat initial: `null` (en cours de v√©rification)
- ‚úÖ √âtat apr√®s v√©rification: `true` (disponible) ou `false` (non disponible)
- ‚úÖ Banni√®re affich√©e uniquement si `false`

### 2. Lien de T√©l√©chargement
- ‚úÖ Lien direct vers: `https://ollama.com/download/windows`
- ‚úÖ Ouvre dans un nouvel onglet (`target="_blank"`)
- ‚úÖ S√©curis√© avec `rel="noopener noreferrer"`
- ‚úÖ Ic√¥ne de t√©l√©chargement pour clart√© visuelle

### 3. Bouton de V√©rification
- ‚úÖ Permet de re-v√©rifier le statut apr√®s installation
- ‚úÖ Met √† jour l'√©tat `isOllamaAvailable`
- ‚úÖ Masque la banni√®re si Ollama est maintenant disponible
- ‚úÖ Ajoute un message de confirmation dans le chat

### 4. Message de Confirmation
Quand Ollama est d√©tect√© apr√®s v√©rification:
```
‚úÖ Ollama est maintenant connect√©! Je suis pr√™t √† vous aider.
```

## Styles Visuels

### ChatBox (√âditeur - Th√®me Clair)
- **Bordure**: Orange 200 (2px)
- **Fond**: Orange 50
- **Texte**: Orange 800/900
- **Ic√¥ne**: Orange 600
- **Bouton principal**: Orange 600 (hover: 700)
- **Bouton secondaire**: Blanc avec bordure orange

### LandingChatBox (Accueil - Th√®me Sombre)
- **Bordure**: Orange 500/50 (2px)
- **Fond**: Orange 900/20
- **Texte**: Orange 200/300
- **Ic√¥ne**: Orange 400
- **Bouton principal**: Orange 600 (hover: 700)
- **Bouton secondaire**: Gray 700 (hover: 600)

## Flux Utilisateur

### Sc√©nario 1: Ollama Non Install√©
```
1. Utilisateur ouvre l'application
   ‚Üì
2. ChatBox v√©rifie le statut Ollama
   ‚Üì
3. Ollama non d√©tect√© (port 11434 inaccessible)
   ‚Üì
4. Banni√®re d'avertissement s'affiche
   ‚Üì
5. Utilisateur clique "T√©l√©charger Ollama"
   ‚Üì
6. Navigateur ouvre ollama.com/download/windows
   ‚Üì
7. Utilisateur t√©l√©charge et installe Ollama
   ‚Üì
8. Utilisateur clique "V√©rifier √† nouveau"
   ‚Üì
9. Ollama d√©tect√© ‚úÖ
   ‚Üì
10. Banni√®re dispara√Æt
    ‚Üì
11. Message de confirmation dans le chat
```

### Sc√©nario 2: Ollama Install√© mais Non D√©marr√©
```
1. Utilisateur ouvre l'application
   ‚Üì
2. ChatBox v√©rifie le statut Ollama
   ‚Üì
3. Ollama non d√©tect√©
   ‚Üì
4. Banni√®re d'avertissement s'affiche
   ‚Üì
5. Utilisateur d√©marre Ollama manuellement
   ‚Üì
6. Utilisateur clique "V√©rifier √† nouveau"
   ‚Üì
7. Ollama d√©tect√© ‚úÖ
   ‚Üì
8. Banni√®re dispara√Æt
```

### Sc√©nario 3: Ollama D√©j√† Disponible
```
1. Utilisateur ouvre l'application
   ‚Üì
2. ChatBox v√©rifie le statut Ollama
   ‚Üì
3. Ollama d√©tect√© ‚úÖ
   ‚Üì
4. Aucune banni√®re affich√©e
   ‚Üì
5. Chat fonctionne normalement
```

## Messages Affich√©s

### Fran√ßais (Par D√©faut)
```
Titre: "Ollama n'est pas d√©tect√©"

Message: "L'assistant AI n√©cessite Ollama pour fonctionner. 
Veuillez installer ou d√©marrer Ollama pour utiliser les 
fonctionnalit√©s d'intelligence artificielle."

Boutons:
- "T√©l√©charger Ollama"
- "V√©rifier √† nouveau"

Astuce: "üí° Apr√®s installation, lancez Ollama et cliquez 
sur 'V√©rifier √† nouveau'"
```

### Anglais (√Ä Impl√©menter)
```
Title: "Ollama not detected"

Message: "The AI assistant requires Ollama to function. 
Please install or start Ollama to use artificial 
intelligence features."

Buttons:
- "Download Ollama"
- "Check Again"

Tip: "üí° After installation, launch Ollama and click 
'Check Again'"
```

## Tests √† Effectuer

### Test 1: Ollama Non Install√©
```bash
# Assurez-vous qu'Ollama n'est pas install√©
# D√©marrez l'application
npm run electron:start

# V√©rifications:
‚úÖ Banni√®re d'avertissement visible dans ChatBox
‚úÖ Banni√®re d'avertissement visible dans LandingChatBox
‚úÖ Lien "T√©l√©charger" fonctionne
‚úÖ Bouton "V√©rifier" fonctionne
```

### Test 2: Ollama Install√© et D√©marr√©
```bash
# D√©marrez Ollama
ollama serve

# D√©marrez l'application
npm run electron:start

# V√©rifications:
‚úÖ Aucune banni√®re affich√©e
‚úÖ Chat fonctionne normalement
‚úÖ Pas d'erreurs dans la console
```

### Test 3: Installation Pendant l'Utilisation
```bash
# D√©marrez l'application sans Ollama
npm run electron:start

# V√©rifications:
‚úÖ Banni√®re visible
# Installez et d√©marrez Ollama
# Cliquez "V√©rifier √† nouveau"
‚úÖ Banni√®re dispara√Æt
‚úÖ Message de confirmation affich√©
```

### Test 4: Ollama Arr√™t√© Pendant l'Utilisation
```bash
# D√©marrez l'application avec Ollama
npm run electron:start

# Arr√™tez Ollama
# Essayez d'utiliser le chat

# V√©rifications:
‚úÖ Erreur de connexion g√©r√©e
‚úÖ Message d'erreur appropri√©
# Red√©marrez Ollama
# Cliquez "V√©rifier √† nouveau"
‚úÖ Fonctionne √† nouveau
```

## Am√©liorations Futures (Optionnel)

### 1. D√©tection en Temps R√©el
- [ ] V√©rifier p√©riodiquement le statut Ollama (toutes les 30s)
- [ ] Afficher/masquer la banni√®re automatiquement
- [ ] Notification quand Ollama devient disponible

### 2. Instructions d'Installation
- [ ] Guide pas √† pas pour installer Ollama
- [ ] D√©tection automatique de l'OS (Windows/Mac/Linux)
- [ ] Liens sp√©cifiques par plateforme

### 3. Diagnostic Avanc√©
- [ ] V√©rifier si le port 11434 est utilis√© par autre chose
- [ ] Sugg√©rer de changer le port si conflit
- [ ] Afficher les logs d'erreur d√©taill√©s

### 4. Mode D√©grad√©
- [ ] Permettre l'utilisation sans Ollama (fonctionnalit√©s limit√©es)
- [ ] Proposer des alternatives (OpenAI, Anthropic)
- [ ] Mode d√©mo avec r√©ponses pr√©-enregistr√©es

## Notes Techniques

### V√©rification du Statut
```typescript
// Fonction utilis√©e pour v√©rifier Ollama
async function checkOllamaStatus(
  endpoint: string = 'http://localhost:11434'
): Promise<boolean> {
  try {
    const response = await fetch(`${endpoint}/api/tags`, {
      method: 'GET',
      signal: AbortSignal.timeout(5000),
    });
    return response.ok;
  } catch {
    return false;
  }
}
```

### Gestion de l'√âtat
```typescript
// √âtat dans le composant
const [isOllamaAvailable, setIsOllamaAvailable] = useState<boolean | null>(null);

// null = en cours de v√©rification
// true = disponible
// false = non disponible
```

### Performance
- ‚úÖ V√©rification unique au montage (pas de polling)
- ‚úÖ Timeout de 5 secondes pour √©viter le blocage
- ‚úÖ Pas d'impact sur les performances si Ollama est disponible

## R√©sum√©

‚úÖ **Composants modifi√©s**: 2 (ChatBox.tsx, LandingChatBox.tsx)  
‚úÖ **Nouvelles d√©pendances**: Aucune (utilise les fonctions existantes)  
‚úÖ **Impact UI**: Banni√®re d'avertissement non intrusive  
‚úÖ **Exp√©rience utilisateur**: Guide clair pour installer Ollama  
‚úÖ **Tests**: Pr√™t pour validation  

L'utilisateur est maintenant guid√© pour installer Ollama s'il n'est pas d√©tect√©! üéâ
