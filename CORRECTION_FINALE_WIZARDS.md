# üîß CORRECTION FINALE - Erreur 404 Wizards avec Ollama

## ‚úÖ DIAGNOSTIC COMPLET

### Situation Actuelle
- ‚úÖ **Ollama fonctionne** : Service actif sur `http://localhost:11434`
- ‚úÖ **Mod√®les install√©s** : `qwen3-vl:4b`, `gemma3:1b`, `llama3.1:8b`, etc.
- ‚ùå **Erreur 404** : L'application ne peut pas g√©n√©rer avec les wizards
- ‚ùå **Cause** : Configuration localStorage corrompue ou pointant vers un mauvais mod√®le

### Erreur Console
```
:11434/api/generate:1 Failed to load resource: the server responded with a status of 404 (Not Found)
```

---

## üéØ SOLUTION IMM√âDIATE (2 MINUTES)

### M√©thode 1: R√©initialisation Rapide via Console

#### √âtape 1: Ouvrir la Console du Navigateur
1. Dans votre navigateur avec l'application ouverte
2. Appuyer sur **F12**
3. Cliquer sur l'onglet **Console**

#### √âtape 2: Copier-Coller ce Code

```javascript
// ============================================================================
// SCRIPT DE R√âINITIALISATION LLM - STORYCORE
// ============================================================================

console.log('üîß D√©but de la r√©initialisation de la configuration LLM...');

// 1. Supprimer l'ancienne configuration
localStorage.removeItem('storycore-llm-config');
console.log('‚úÖ Ancienne configuration supprim√©e');

// 2. Cr√©er une nouvelle configuration propre avec qwen3-vl:4b
const newConfig = {
  provider: 'local',
  model: 'qwen3-vl:4b',
  apiKey: '',
  apiEndpoint: 'http://localhost:11434',
  streamingEnabled: true,
  parameters: {
    temperature: 0.7,
    maxTokens: 2000,
    topP: 0.9,
    frequencyPenalty: 0,
    presencePenalty: 0
  },
  systemPrompts: {
    worldGeneration: 'You are a creative world-building assistant...',
    characterGeneration: 'You are a character development expert...',
    dialogueGeneration: 'You are a dialogue writing specialist...'
  },
  timeout: 30000,
  retryAttempts: 3
};

// 3. Sauvegarder la nouvelle configuration
localStorage.setItem('storycore-llm-config', JSON.stringify(newConfig));
console.log('‚úÖ Nouvelle configuration sauvegard√©e:', newConfig);

// 4. V√©rifier que la configuration est bien enregistr√©e
const savedConfig = JSON.parse(localStorage.getItem('storycore-llm-config'));
console.log('‚úÖ Configuration v√©rifi√©e:', savedConfig);

console.log('üéâ R√©initialisation termin√©e! Rechargement de la page...');

// 5. Recharger la page
setTimeout(() => location.reload(), 1000);
```

#### √âtape 3: Appuyer sur Entr√©e

La page va se recharger automatiquement apr√®s 1 seconde.

#### √âtape 4: Tester

1. Ouvrir un wizard (World Building, Character, etc.)
2. Le banner jaune devrait avoir disparu
3. Cliquer sur un bouton de g√©n√©ration AI (ex: "Generate World Concept")
4. ‚úÖ √áa devrait fonctionner!

---

## üîç V√âRIFICATION POST-CORRECTION

### Test 1: V√©rifier la Configuration dans la Console

```javascript
// Afficher la configuration actuelle
const config = JSON.parse(localStorage.getItem('storycore-llm-config'));
console.table({
  'Provider': config.provider,
  'Model': config.model,
  'Endpoint': config.apiEndpoint,
  'Streaming': config.streamingEnabled
});
```

**R√©sultat attendu:**
```
Provider:  local
Model:     qwen3-vl:4b
Endpoint:  http://localhost:11434
Streaming: true
```

### Test 2: Tester Ollama Directement

Dans PowerShell:
```powershell
# Test 1: V√©rifier que le mod√®le existe
ollama list

# Test 2: Tester la g√©n√©ration
ollama run qwen3-vl:4b "Bonjour, comment vas-tu?"

# Test 3: Tester l'API
curl -X POST http://localhost:11434/api/generate -H "Content-Type: application/json" -d "{\"model\":\"qwen3-vl:4b\",\"prompt\":\"Hello\",\"stream\":false}"
```

### Test 3: V√©rifier les Logs de l'Application

Dans la console du navigateur (F12), vous devriez voir:
```
[LLMProvider] Initializing LLM service...
[LLMProvider] Checking Ollama availability at http://localhost:11434
[LLMProvider] Ollama is available
[LLMProvider] LLM service initialized successfully
```

---

## üõ†Ô∏è M√âTHODE ALTERNATIVE: Configuration Manuelle

Si la m√©thode console ne fonctionne pas, vous pouvez configurer manuellement:

### Option A: Via l'Interface de l'Application

1. **Ouvrir les Param√®tres**
   - Cliquer sur l'ic√¥ne ‚öôÔ∏è (Settings) dans l'application
   - Aller dans **LLM Configuration**

2. **Configurer Ollama**
   - **Provider**: S√©lectionner "Local LLM"
   - **API Endpoint**: `http://localhost:11434`
   - **Model**: S√©lectionner `qwen3-vl:4b` dans la liste
   - **Temperature**: 0.7
   - **Max Tokens**: 2000
   - **Streaming**: Activ√© (coch√©)

3. **Sauvegarder**
   - Cliquer sur **Save** ou **Apply**
   - Fermer les param√®tres

### Option B: √âditer localStorage Manuellement

Dans la console du navigateur:

```javascript
// Configuration minimale
localStorage.setItem('storycore-llm-config', JSON.stringify({
  provider: 'local',
  model: 'qwen3-vl:4b',
  apiEndpoint: 'http://localhost:11434'
}));

location.reload();
```

---

## üêõ D√âPANNAGE AVANC√â

### Probl√®me 1: Le Mod√®le n'Appara√Æt Pas dans la Liste

**Solution:**
```powershell
# V√©rifier les mod√®les install√©s
ollama list

# Si qwen3-vl:4b n'est pas l√†, le t√©l√©charger
ollama pull qwen3-vl:4b
```

### Probl√®me 2: Ollama ne R√©pond Pas

**V√©rifier le service:**
```powershell
# V√©rifier si Ollama √©coute sur le port 11434
netstat -an | findstr "11434"
```

**R√©sultat attendu:**
```
TCP    0.0.0.0:11434          0.0.0.0:0              LISTENING
```

**Si le port n'est pas ouvert:**
```powershell
# Red√©marrer Ollama
ollama serve
```

### Probl√®me 3: Erreur CORS

Si vous voyez une erreur CORS dans la console:

**Solution:**
```powershell
# Arr√™ter Ollama
taskkill /F /IM ollama.exe

# Red√©marrer avec CORS activ√©
$env:OLLAMA_ORIGINS="*"
ollama serve
```

### Probl√®me 4: Configuration ne se Sauvegarde Pas

**V√©rifier les permissions localStorage:**
```javascript
// Test d'√©criture
try {
  localStorage.setItem('test', 'test');
  localStorage.removeItem('test');
  console.log('‚úÖ localStorage fonctionne');
} catch (e) {
  console.error('‚ùå localStorage bloqu√©:', e);
}
```

**Si bloqu√©:**
- V√©rifier les param√®tres de confidentialit√© du navigateur
- D√©sactiver le mode navigation priv√©e
- Autoriser les cookies et le stockage local

---

## üìä CHECKLIST DE V√âRIFICATION

Apr√®s avoir appliqu√© la correction, v√©rifier:

- [ ] ‚úÖ Ollama fonctionne (`ollama list` dans PowerShell)
- [ ] ‚úÖ Le mod√®le `qwen3-vl:4b` est install√©
- [ ] ‚úÖ La configuration localStorage est correcte (voir Test 1)
- [ ] ‚úÖ L'application se connecte √† Ollama (voir logs console)
- [ ] ‚úÖ Le banner jaune a disparu des wizards
- [ ] ‚úÖ Les boutons de g√©n√©ration AI sont actifs
- [ ] ‚úÖ La g√©n√©ration fonctionne (test avec World Building)

---

## üéØ R√âSULTAT ATTENDU

### Avant la Correction
```
‚ùå Erreur 404 sur /api/generate
‚ùå Banner jaune "LLM not configured"
‚ùå Boutons de g√©n√©ration d√©sactiv√©s
```

### Apr√®s la Correction
```
‚úÖ Connexion √† Ollama r√©ussie
‚úÖ Pas de banner d'erreur
‚úÖ Boutons de g√©n√©ration actifs
‚úÖ G√©n√©ration AI fonctionnelle
```

---

## üìù COMMANDES RAPIDES DE R√âF√âRENCE

### R√©initialisation Express (Console Navigateur)
```javascript
localStorage.removeItem('storycore-llm-config');
localStorage.setItem('storycore-llm-config', JSON.stringify({provider:'local',model:'qwen3-vl:4b',apiEndpoint:'http://localhost:11434',streamingEnabled:true,parameters:{temperature:0.7,maxTokens:2000,topP:0.9,frequencyPenalty:0,presencePenalty:0}}));
location.reload();
```

### V√©rification Express (Console Navigateur)
```javascript
console.log(JSON.parse(localStorage.getItem('storycore-llm-config')));
```

### Test Ollama Express (PowerShell)
```powershell
ollama list
curl http://localhost:11434/api/tags
```

---

## üÜò BESOIN D'AIDE?

Si le probl√®me persiste apr√®s avoir suivi toutes ces √©tapes:

1. **Copier les logs de la console** (F12 ‚Üí Console ‚Üí Clic droit ‚Üí Save as...)
2. **Copier la sortie de** `ollama list`
3. **Copier la configuration** (voir V√©rification Test 1)
4. **Partager ces informations** pour un diagnostic plus approfondi

---

## ‚úÖ PROCHAINES √âTAPES

Une fois la correction appliqu√©e et fonctionnelle:

1. **Tester tous les wizards**
   - World Building Wizard
   - Character Wizard
   - Generic Wizard

2. **V√©rifier les fonctionnalit√©s AI**
   - G√©n√©ration de concepts
   - G√©n√©ration de descriptions
   - Suggestions automatiques

3. **Optimiser si n√©cessaire**
   - Ajuster la temp√©rature (0.5-1.0)
   - Ajuster max_tokens selon vos besoins
   - Tester d'autres mod√®les (gemma3:1b pour plus de vitesse)

---

**üéâ Bonne chance! La correction devrait prendre moins de 2 minutes avec la m√©thode console.**
