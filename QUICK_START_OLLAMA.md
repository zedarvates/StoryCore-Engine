# Quick Start - Ollama avec Gemma 3

## Installation Rapide

### 1. Installer Ollama
```bash
# Windows: T√©l√©charger depuis
https://ollama.com/download/windows

# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. D√©marrer Ollama
```bash
ollama serve
```

### 3. Installer un Mod√®le
```bash
# Recommand√© pour la plupart des syst√®mes
ollama pull gemma3:4b

# Ou pour syst√®mes avec moins de RAM
ollama pull gemma3:1b

# Ou pour syst√®mes puissants
ollama pull gemma3:12b
```

### 4. D√©marrer StoryCore
```bash
# Retourner √† la racine du projet
cd C:\storycore-engine

# D√©marrer l'application
npm run electron:start
```

## V√©rification

Dans la console, vous devriez voir:
```
‚úÖ Ollama initialized with Gemma 3 4B
üìç Endpoint: http://localhost:11434
ü§ñ Model: gemma3:4b
üöÄ StoryCore ready with Gemma 3 4B
```

## Si Ollama N'est Pas D√©tect√©

L'application affichera un message dans les ChatBox avec:
- üîó Lien de t√©l√©chargement direct
- üîÑ Bouton "V√©rifier √† nouveau"
- üí° Instructions d'installation

## S√©lection Automatique du Mod√®le

L'application choisit automatiquement le meilleur mod√®le selon votre syst√®me:

| Votre RAM | Mod√®le S√©lectionn√© |
|-----------|-------------------|
| < 6 GB | Gemma 3 1B |
| 6-16 GB | Gemma 3 4B ‚≠ê |
| > 16 GB | Gemma 3 12B |

## Commandes Utiles

```bash
# V√©rifier qu'Ollama fonctionne
curl http://localhost:11434/api/tags

# Lister les mod√®les install√©s
ollama list

# Tester un mod√®le
ollama run gemma3:4b "Hello!"

# Supprimer un mod√®le
ollama rm gemma3:1b
```

## Documentation Compl√®te

- **Guide utilisateur**: `OLLAMA_CONFIGURATION.md`
- **Documentation technique**: `OLLAMA_IMPLEMENTATION_SUMMARY.md`
- **R√©sum√© complet**: `SESSION_COMPLETE_OLLAMA.md`

C'est tout! üéâ
