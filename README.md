# ğŸ¬ StoryCore-Engine
### The Self-Correcting Multimodal Production Pipeline

**From Script to Screen in Minutes â€” With  Visual Coherence**

![Hackathon 2026](https://img.shields.io/badge/Hackathon-2026-blue) ![Python](https://img.shields.io/badge/Python-3.9+-green) ![React](https://img.shields.io/badge/React-18+-blue) ![ComfyUI](https://img.shields.io/badge/ComfyUI-Ready-orange) ![Deterministic AI](https://img.shields.io/badge/Deterministic-AI-purple) ![Security](https://img.shields.io/badge/Security-Validated-green) ![Resilience](https://img.shields.io/badge/Resilience-Enterprise-blue)![Python](https://img.shields.io/badge/python-3.11+-blue)
![License](https://img.shields.io/github/license/zedarvates/StoryCore-Engine)
![Repo size](https://img.shields.io/github/repo-size/zedarvates/StoryCore-Engine)

---

![StoryCore-Engine Preview](assets/Screenshot%202026-02-15%20060825.png)

---

> **A Message from the Creator**
StoryCore is more than just a pipeline.
Itâ€™s a system that lets you control ComfyUI or other tools through addâ€‘ons.
It helps you organize your entire workflow for video creation â€” from the written story, to the script, to the dialogue.
From 3D scene creation, to image generation, to textâ€‘toâ€‘image, to video, all the way to your cinematic work.
From long takes to individual shots, from visual planning to music.
From style to theme to genre â€” whatever you want to use.
Automation or semiâ€‘automation powered by AI accelerates your entire creative process.

>The future of the internet? And of cinema? Itâ€™s onâ€‘demand videos built according to peopleâ€™s tastes. According to each customer. Directly on their TV. Basically, itâ€™s instant, madeâ€‘toâ€‘order cinema. But weâ€™ll only really see that in five to ten years, I think.
For now, in any video you create, you have to tell a story. If itâ€™s sloppy, meaningless content or just random life footage with no intention behind it, thereâ€™s no real reason for anyone to watch your videoâ€”except maybe for the emotional manipulation, where youâ€™re really trying to influence the viewerâ€™s mind

> I wanted to create a tool that modernizes longâ€‘form video production without losing the soul of the craft. We start from the classic storyboard methodsâ€”the ones that shaped generations of creatorsâ€”and we bring them into the present with the tools of our era.
>
> This isn't just another AI generator. It's a complete production pipeline: storyboard, visual coherence, narrative continuity, scene organization, character tracking, location consistency. The system remembers the entire project, just like a full team dedicated to artistic supervision.
>
> But above all, it respects the creators. The goal is not to replace artists, but to give them back time, freedom, and control. AI handles the repetitive tasks, while humans keep the vision, the emotion, and the direction. With this approach, a project that once required thirty people can now be handled by six to eight, allowing the rest of the team to focus on more creative, more human, and more meaningful work.
>
> And everything runs locally. Your data, your images, your scripts, your industrial secretsâ€”everything stays on your machine. It's a sovereign tool, designed for studios, agencies, and independent creators who must protect their work. In a world where uploading a single file online is already a risk, I wanted to offer a safer, modern, and respectful alternative.
>
> In short, I wanted to build a bridge between yesterday and today: the rigor and poetry of traditional methods, combined with the speed and power of modern tools. A tool that accelerates production, secures your workflow, and frees creativity.

On top of all that, Iâ€™ve added an automated system for scientific checks.
If youâ€™re working on documentaries, this can be extremely useful â€” or even for scienceâ€‘fiction projects.
There are still a few adjustments to make to make the output a bit less strictly scientific, because right now it tends to be a little rigid on that part.
These refinements will be handled in future versions.

---

[![StoryCore Presentation Video](assets/Screenshot%202026-02-15%20060805.png)](https://www.youtube.com/watch?v=P0K7DueyICo)

---

## ğŸ“‹ System Requirements

### Minimum Hardware
- **Display**: 1 screen, mouse, keyboard (microphone optional)
- **GPU**: NVIDIA RTX 3060 with 12GB VRAM (RTX 4070+ recommended)
- **RAM**: 32GB system memory
- **Storage**: ~500GB (includes ComfyUI models)
- **Software**: CUDA, PyTorch, Python 3.11+, latest GPU drivers

note : Be careful: even with an RTX 5060 and 32 GB of RAM â€” a fairly recent PC â€” generating a single image can take around 5 minutes. Generating a video can take anywhere from 15 to 30 minutes. Creating background music can take about 5 minutes.
As for dialogue generation, it will obviously depend on the length of the dialogue and the variables you apply. And on top of that, you might also add filters. As of right now, Iâ€™m not even sure if Iâ€™ve already integrated those filters into the user interface.

---
![StoryCore Interface](assets/Screenshot%202026-02-15%20060805.png)

![StoryCore Dashboard](assets/Screenshot%202026-02-15%20060909.png)

![StoryCore Editor](assets/Screenshot%202026-02-15%20060938.png)


---
## ğŸš€ Quick Start

> **New to the project?** Start with [START_HERE.md](START_HERE.md) for guided navigation based on your role.

### Prerequisites

**Required Components:**
- **Graphics Card** - Minimum RTX 3060 with 12GB VRAM (recommended RTX 4070+ for optimal performance)
- **ComfyUI** - For AI image/video generation (download from [comfyanonymous.github.io](https://comfyanonymous.github.io/ComfyUI_get/))

Key Info:

ComfyUI Desktop uses port 8000
Manual ComfyUI uses port 8188
Full guides: Quick Start | Desktop Setup



- **Ollama** - For local LLM processing (download from [ollama.com](https://ollama.com/))

Both tools run locally and keep all your data secure on your machine.

### Installation

```bash
# Clone the repository
git clone https://github.com/zedarvates/StoryCore-Engine.git
cd storycore-engine

# Install dependencies
pip install -r requirements.txt
npm install

# Run the application
python storycore.py
```

### Basic Usage

```bash
# Initialize a new project
python storycore.py init my-project

# Generate visual coherence grid
python storycore.py grid --project my-project

# Run the full pipeline
python storycore.py promote --project my-project
```

---

## âœ¨ Key Features

### Core Features
- **Visual Coherence System** - Master Coherence Sheet ensures consistent style across all frames
- **Story Builder System** - Master story ensures coherence across video projects
- **Self-Correcting Pipeline** - Automatic quality detection and fixing during generation
- **Deterministic Output** - Reproducible results with seed control
- **Complete Local Processing** - No cloud dependencies, all data stays on your machine
- **Production-Ready** - Security validation, error handling, and resilience patterns

### AI Integration
- **ComfyUI Integration** - Full support for ComfyUI Desktop (port 8000) and Manual (port 8188)
- **LLM Support** - Ollama integration for local LLM processing (Qwen, Gemma, etc.)
- **Image Generation** - NewBie, Qwen models via ComfyUI workflows
- **Video Generation** - HunyuanVideo, Wan Video integration
- **Audio Processing** - Dialogue generation, background music, audio effects

### Creative Tools
- **Wizard System** - Modular wizards for characters, locations, objects, scenes
- **Sequence Editor** - Video and audio timeline editing
- **Character Portraits** - AI-powered character generation with consistency
- **Camera Angles** - Camera movement planning and transitions
- **3D Scene Creation** - Integration with 3D tools for scene planning

### Add-on System
- **Extensible Architecture** - Control ComfyUI and other tools through add-ons
- **Custom Workflows** - Create and share custom ComfyUI workflows
- **Plugin Support** - Extend functionality with community plugins

---

## ğŸ—ï¸ Architecture

```
ğŸ“ Input (Script/Prompt)
    â†“
ğŸ§  Story Engine
    â”œâ”€â”€ LLM Processing (Ollama)
    â”œâ”€â”€ Scene Breakdown
    â”œâ”€â”€ Character Development
    â””â”€â”€ Dialogue Generation
    â†“
ğŸ¨ Visual Planning
    â”œâ”€â”€ Visual Coherence Grid (ComfyUI)
    â”œâ”€â”€ Character Portraits
    â”œâ”€â”€ Location Design
    â””â”€â”€ Shot Planning
    â†“
ğŸ¬ Production Pipeline
    â”œâ”€â”€ Image Generation (NewBie, Qwen, Flux)
    â”œâ”€â”€ Video Generation (HunyuanVideo, Wan Video)
    â”œâ”€â”€ Audio Generation (Music, Dialogue, Effects)
    â””â”€â”€ Quality Check & Auto-fix
    â†“
ğŸ“¦ Export
    â”œâ”€â”€ Video Output (MP4, WebM)
    â”œâ”€â”€ Audio Tracks
    â””â”€â”€ Project Files
```

### Technology Stack

| Layer | Technologies |
|-------|-------------|
| **Frontend** | React 18+, TypeScript, Tailwind CSS, Electron, Vite |
| **Backend** | FastAPI, Python 3.11+, Pydantic, Uvicorn |
| **AI/ML** | ComfyUI, Ollama, PyTorch, CUDA, NumPy |
| **Video** | FFmpeg, HunyuanVideo, Wan Video, OpenCV |
| **Audio** | Custom audio processing, TTS integration, Audio remix engine |
| **3D** | Panda3D, Open3D, OpenGL (optional) |
| **Storage** | Local filesystem, SQLite, JSON |
| **State Management** | Zustand, Redux Toolkit |

### ComfyUI Integration Layer

**Production-Ready Features:**
- âœ… Advanced Workflows with 8+ AI Models
- âœ… Circuit Breaker for fault tolerance
- âœ… Fallback Chains for graceful degradation
- âœ… Error Analytics for monitoring
- âœ… Validated Performance Metrics
- âœ… WebSocket real-time communication
- âœ… Automatic retry with exponential backoff
- âœ… GPU memory management

**Supported Models:**

| Type | Models |
|------|--------|
| **Image Generation** | Flux, SDXL, NewBie, Qwen, Stable Diffusion |
| **Video Generation** | HunyuanVideo, Wan Video, LTX2 |
| **LLM** | Qwen, Gemma, Llama (via Ollama) |
| **Audio** | Custom TTS models, Music generation |

---
note : If youâ€™re really in a hurry and you have Grok accounts, a Seeddance King account, and all the rest of that ecosystem â€” and if your video is just for testing and not a production at the peak of your capabilities â€” then itâ€™s better to use those tools.
You can still rely on StoryCore to build the foundation, the story, and all that, because as of right now, they donâ€™t yet have all the features Iâ€™ve added for creating longâ€‘form videos. So you take the preâ€‘generated prompts from StoryCore, and you can run everything on their platform as your project progresses. Thatâ€™s also a valid workflow.

---
## ğŸ›¡ï¸ Error Handling & Resilience

StoryCore-Engine includes comprehensive error handling and resilience patterns for production reliability.

**Resilience Patterns:**
- Retry Mechanism with exponential backoff
- Circuit Breaker for fault tolerance
- Fallback Chains for graceful degradation
- Error Analytics for monitoring

---

## ğŸ“ Project Structure

```
storycore-engine/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ storycore.py              # Main CLI entry point
â”œâ”€â”€ backend/                  # FastAPI backend services
â”‚   â”œâ”€â”€ main_api.py           # API server entry point
â”‚   â”œâ”€â”€ llm_api.py            # LLM integration endpoints
â”‚   â”œâ”€â”€ project_api.py        # Project management API
â”‚   â”œâ”€â”€ video_editor_api.py   # Video editing endpoints
â”‚   â””â”€â”€ ...                   # Additional API modules
â”œâ”€â”€ src/                      # Core engine modules
â”‚   â”œâ”€â”€ grid_generator.py     # Visual coherence generation
â”‚   â”œâ”€â”€ promotion_engine.py   # Content promotion pipeline
â”‚   â”œâ”€â”€ qa_engine.py          # Quality assessment
â”‚   â”œâ”€â”€ video_engine.py       # Video processing
â”‚   â”œâ”€â”€ comfyui_manager.py    # ComfyUI integration
â”‚   â”œâ”€â”€ narrative_engine.py   # Story processing
â”‚   â””â”€â”€ ...                   # Additional engine modules
â”œâ”€â”€ creative-studio-ui/       # React/TypeScript frontend
â”œâ”€â”€ workflows/                # ComfyUI workflow definitions
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ documentation/            # Technical documentation
â””â”€â”€ tests/                    # Test suite
```

---

## ğŸ”§ Development

### Building the Application

**Production Build:**
```bash
# Build UI and Electron app
npm run build

# Package for distribution
npm run package:win   # Windows
npm run package:mac   # macOS
npm run package:linux # Linux
```

**Build Status:** âœ… All builds passing
- UI Build: ~8s
- Electron Build: Complete
- TypeScript: No errors
- Bundle Size: 1.38 MB (356 KB gzipped)

**For detailed build information, see:** [BUILD_REPORT.md](documentation/reports/BUILD_REPORT.md)


---

## ğŸ¯ Future Roadmap

### ğŸ“Š Current Status (February 2026)

**Completed Features:**
- âœ… Visual Coherence System
- âœ… Story Builder System
- âœ… ComfyUI Integration (Desktop & Manual)
- âœ… Wizard System (Characters, Locations, Objects, Scenes)
- âœ… Sequence Editor
- âœ… LLM Integration (Ollama)
- âœ… Image Generation (Flux, SDXL, NewBie, Qwen)
- âœ… Video Generation (HunyuanVideo, Wan Video)
- âœ… Audio Processing & Dialogue Generation
- âœ… Add-on System
- âœ… Security Validation & Error Handling

### ğŸ“Š Visual Roadmap

| Phase | Feature | Status | Description |
|-------|---------|--------|-------------|
| **Q1 2026** | Image Generation Dialog Enhancement | ğŸ”„ In Progress | Improved UI for image generation |
| **Q1 2026** | Dashboard Wizard Addon | ğŸ”„ In Progress | Enhanced dashboard functionality |
| **Q1 2026** | Advanced Camera Movements | ğŸ”œ Planned | Bezier curves and complex transitions |
| **Q2 2026** | Multi-format Export | ğŸ”œ Planned | MP4 generation from video plans |
| **Q2 2026** | Performance Optimization | ğŸ”œ Planned | Parallel processing and caching |
| **Q3 2026** | Collaborative Features | ğŸ“‹ Backlog | Multi-user project management |
| **Q3 2026** | Plugin Architecture | ğŸ“‹ Backlog | Custom engine extensions |
| **Q4 2026** | Cloud Deployment | ğŸ“‹ Backlog | Scalable cloud infrastructure |
| **Q4 2026** | Real-time Monitoring | ğŸ“‹ Backlog | Enhanced monitoring with alerting |
| **2027** | Multi-character Scenes | ğŸ“‹ Backlog | Advanced scene composition |
| **2027** | Studio Integration | ğŸ“‹ Backlog | Enterprise deployment and scaling |

### ğŸ“‹ Milestone List

1. **v1.1.0** - Image Generation Dialog & Dashboard Enhancements (Q1 2026)
2. **v1.2.0** - Advanced Camera Movements & Transitions (Q1 2026)
3. **v1.3.0** - Multi-format Export (MP4) (Q2 2026)
4. **v1.4.0** - Performance Optimization (Q2 2026)
5. **v2.0.0** - Collaborative Features & Plugin Architecture (Q3-Q4 2026)

---

**Focus Areas for 2026:**
- ğŸ¨ **UI/UX Improvements** - Enhanced wizards, better dialogs, improved accessibility
- âš¡ **Performance** - Faster generation, better caching, GPU optimization
- ğŸ”Œ **Extensibility** - Plugin system, custom workflows, API expansion
- ğŸ¤ **Collaboration** - Multi-user support, project sharing, team features

---

## ğŸ“š Documentation

### Getting Started
- [Quick Start Guide](documentation/user_guide/comfyui_integration/COMFYUI_QUICK_START.md) - ComfyUI setup in 2 minutes
- [Documentation Index](INDEX_DOCUMENTATION_COMPLETE.md) - ğŸ“‘ **START HERE** - Complete documentation navigation
- [Quick Reference](QUICK_REFERENCE.md) - Common commands and workflows

### Build & Development
- [Build Success Summary](documentation/reports/BUILD_SUCCESS_SUMMARY.md) - âœ… Latest build status (Jan 23, 2026)
- [Build Report](documentation/reports/BUILD_REPORT.md) - Detailed build analysis and metrics
- [Release Notes](documentation/RELEASE_NOTES_2026_01_23.md) - Latest release information
- [Changelog](CHANGELOG.md) - Version history

### Technical Documentation
- [Technical Guide](documentation/TECHNICAL_GUIDE.md) - Architecture and implementation
- [API Reference](documentation/api_reference/README.md) - API documentation
- [Troubleshooting](documentation/TROUBLESHOOTING.md) - Common issues and solutions
- [Project Index](INDEX.md) - Complete project structure



---

## ğŸ… Built for Hackathon 2026

**Team:** StoryCore-Engine Development Team  
**Duration:** 210+ hours  
**Focus:** Coherence-first, measurable multimodal pipeline  
**Result:** Production-ready system with professional interfaces

*Redefining how creators interact with multimodal AI through guaranteed visual coherence and autonomous quality control.*
