# ğŸ¬ StoryCore-Engine
### The Self-Correcting Multimodal Production Pipeline

**From Script to Screen in 5 Minutes â€” With  Visual Coherence**

![Hackathon 2026](https://img.shields.io/badge/Hackathon-2026-blue) ![Python](https://img.shields.io/badge/Python-3.9+-green) ![React](https://img.shields.io/badge/React-18+-blue) ![ComfyUI](https://img.shields.io/badge/ComfyUI-Ready-orange) ![Deterministic AI](https://img.shields.io/badge/Deterministic-AI-purple) ![Security](https://img.shields.io/badge/Security-Validated-green) ![Resilience](https://img.shields.io/badge/Resilience-Enterprise-blue)![Python](https://img.shields.io/badge/python-3.11+-blue)
![License](https://img.shields.io/github/license/zedarvates/StoryCore-Engine)
![Repo size](https://img.shields.io/github/repo-size/zedarvates/StoryCore-Engine)

---

![Preview](assets/Screenshot-2026-02-15-060825.png)


---

> **A Message from the Creator**
StoryCore is more than just a pipeline.
Itâ€™s a system that lets you control ComfyUI or other tools through addâ€‘ons.
It helps you organize your entire workflow for video creation â€” from the written story, to the script, to the dialogue.
From 3D scene creation, to image generation, to textâ€‘toâ€‘image, to video, all the way to your cinematic work.
From long takes to individual shots, from visual planning to music.
From style to theme to genre â€” whatever you want to use.
Automation or semiâ€‘automation powered by AI accelerates your entire creative process.

>The future of the internet? And of cinema? Itâ€™s onâ€‘demand videos built according to peopleâ€™s tastes. According to each customer. Directly on their TV. Basically, itâ€™s instant, madeâ€‘toâ€‘order cinema. But weâ€™ll only really see that in five to ten years, I think.
For now, in any video you create, you have to tell a story. If itâ€™s sloppy, meaningless content or just random life footage with no intention behind it, thereâ€™s no real reason for anyone to watch your videoâ€”except maybe for the emotional manipulation, where youâ€™re really trying to influence the viewerâ€™s mind

> I wanted to create a tool that modernizes longâ€‘form video production without losing the soul of the craft. We start from the classic storyboard methodsâ€”the ones that shaped generations of creatorsâ€”and we bring them into the present with the tools of our era.
>
> This isn't just another AI generator. It's a complete production pipeline: storyboard, visual coherence, narrative continuity, scene organization, character tracking, location consistency. The system remembers the entire project, just like a full team dedicated to artistic supervision.
>
> But above all, it respects the creators. The goal is not to replace artists, but to give them back time, freedom, and control. AI handles the repetitive tasks, while humans keep the vision, the emotion, and the direction. With this approach, a project that once required thirty people can now be handled by six to eight, allowing the rest of the team to focus on more creative, more human, and more meaningful work.
>
> And everything runs locally. Your data, your images, your scripts, your industrial secretsâ€”everything stays on your machine. It's a sovereign tool, designed for studios, agencies, and independent creators who must protect their work. In a world where uploading a single file online is already a risk, I wanted to offer a safer, modern, and respectful alternative.
>
> In short, I wanted to build a bridge between yesterday and today: the rigor and poetry of traditional methods, combined with the speed and power of modern tools. A tool that accelerates production, secures your workflow, and frees creativity.

On top of all that, Iâ€™ve added an automated system for scientific checks.
If youâ€™re working on documentaries, this can be extremely useful â€” or even for scienceâ€‘fiction projects.
There are still a few adjustments to make to make the output a bit less strictly scientific, because right now it tends to be a little rigid on that part.
These refinements will be handled in future versions.

---

![ presentation ](assets/Screenshot-2026-02-15060805.png.png)][(https://www.youtube.com/watch?v=P0K7DueyICo](https://youtu.be/P0K7DueyICo?si=kEvpsxMy4zeFEYqO))


---

## ğŸ“‹ System Requirements

### Minimum Hardware
- **Display**: 1 screen, mouse, keyboard (microphone optional)
- **GPU**: NVIDIA RTX 3060 with 12GB VRAM (RTX 4070+ recommended)
- **RAM**: 32GB system memory
- **Storage**: ~500GB (includes ComfyUI models)
- **Software**: CUDA, PyTorch, Python 3.11+, latest GPU drivers

note : Be careful: even with an RTX 5060 and 32 GB of RAM â€” a fairly recent PC â€” generating a single image can take around 5 minutes. Generating a video can take anywhere from 15 to 30 minutes. Creating background music can take about 5 minutes.
As for dialogue generation, it will obviously depend on the length of the dialogue and the variables you apply. And on top of that, you might also add filters. As of right now, Iâ€™m not even sure if Iâ€™ve already integrated those filters into the user interface.

---
![Preview](assets/Screenshot-2026-02-15060805.png)

![Preview](assets/Screenshot-2026-02-15-060909.png)

![Preview](assets/Screenshot-2026-02-15-060938.png)

---
## ğŸš€ Quick Start

> **New to the project?** Start with [START_HERE.md](START_HERE.md) for guided navigation based on your role.

### Prerequisites

**Required Components:**
- **Graphics Card** - Minimum RTX 3060 with 12GB VRAM (recommended RTX 4070+ for optimal performance)
- **ComfyUI** - For AI image/video generation (download from [comfyanonymous.github.io](https://comfyanonymous.github.io/ComfyUI_get/))

Key Info:

ComfyUI Desktop uses port 8000
Manual ComfyUI uses port 8188
Full guides: Quick Start | Desktop Setup



- **Ollama** - For local LLM processing (download from [ollama.com](https://ollama.com/))

Both tools run locally and keep all your data secure on your machine.

### Installation

```bash
# Clone the repository
git clone https://github.com/zedarvates/StoryCore-Engine.git
cd storycore-engine

# Install dependencies
pip install -r requirements.txt
npm install

# Run the application
python storycore.py
```

### Basic Usage

```bash
# Initialize a new project
python storycore.py init my-project

# Generate visual coherence grid
python storycore.py grid --project my-project

# Run the full pipeline
python storycore.py promote --project my-project
```

---

## âœ¨ Key Features

- **Visual Coherence System** - Master Coherence Sheet ensures consistent style across all frames
- **Story builder System** - Master story ensures  coherences across video
- **Self-Correcting Pipeline** - Automatic quality detection and fixing during generation
- **Deterministic Output** - Reproducible results with seed control
- **Complete Local Processing** - No cloud dependencies, all data stays on your machine
- **Production-Ready** - Security validation, error handling, and resilience patterns

---

## ğŸ—ï¸ Architecture

```
ğŸ“ Input (Script/Prompt)  â†’ ğŸ§  Text Engine (Scene Breakdown + Shot Planning)
    â†“
ğŸ§  LLM Processing (Ollama) â†’ Scene Breakdown
    â†“
ğŸ¨ Visual Coherence Grid (ComfyUI) ğŸ”€ Workflow Selection (Basic/Advanced)
    â†“
âš¡ Quality Check & Auto-fix
    â†“
ğŸ”§ AutofixEngine (Parameter Adjustment + Re-processing Loop)
    â†“
ğŸ¬ Video Planning (Camera Movements + Transitions)
    â†“    
ğŸ¬ Video Generation (HunyuanVideo, Wan Video) | ğŸ–¼ï¸ Image Generation (NewBie, Qwen)
    â†“
ğŸ“¦ Export Ready Output
```

ComfyUI Integration Layer (Production-Ready)

Advanced Workflows ( + 8 AI Models)
Data Flow & Performance
Validated Performance Metrics
Circuit Breaker
Fallback Chains
Graceful Degradation
Error Analytics

---
note : If youâ€™re really in a hurry and you have Grok accounts, a Seeddance King account, and all the rest of that ecosystem â€” and if your video is just for testing and not a production at the peak of your capabilities â€” then itâ€™s better to use those tools.
You can still rely on StoryCore to build the foundation, the story, and all that, because as of right now, they donâ€™t yet have all the features Iâ€™ve added for creating longâ€‘form videos. So you take the preâ€‘generated prompts from StoryCore, and you can run everything on their platform as your project progresses. Thatâ€™s also a valid workflow.

---
## ğŸ›¡ï¸ Error Handling & Resilience

StoryCore-Engine includes comprehensive error handling and resilience patterns for production reliability.

**Resilience Patterns:**
- Retry Mechanism with exponential backoff
- Circuit Breaker for fault tolerance
- Fallback Chains for graceful degradation
- Error Analytics for monitoring

---

## ğŸ“ Project Structure

```
storycore-engine/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ storycore.py              # Main CLI entry point
â”œâ”€â”€ backend/                  # FastAPI backend services
â”‚   â”œâ”€â”€ main_api.py           # API server entry point
â”‚   â”œâ”€â”€ llm_api.py            # LLM integration endpoints
â”‚   â”œâ”€â”€ project_api.py        # Project management API
â”‚   â”œâ”€â”€ video_editor_api.py   # Video editing endpoints
â”‚   â””â”€â”€ ...                   # Additional API modules
â”œâ”€â”€ src/                      # Core engine modules
â”‚   â”œâ”€â”€ grid_generator.py     # Visual coherence generation
â”‚   â”œâ”€â”€ promotion_engine.py   # Content promotion pipeline
â”‚   â”œâ”€â”€ qa_engine.py          # Quality assessment
â”‚   â”œâ”€â”€ video_engine.py       # Video processing
â”‚   â”œâ”€â”€ comfyui_manager.py    # ComfyUI integration
â”‚   â”œâ”€â”€ narrative_engine.py   # Story processing
â”‚   â””â”€â”€ ...                   # Additional engine modules
â”œâ”€â”€ creative-studio-ui/       # React/TypeScript frontend
â”œâ”€â”€ workflows/                # ComfyUI workflow definitions
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ documentation/            # Technical documentation
â””â”€â”€ tests/                    # Test suite
```

---

## ğŸ”§ Development

### Building the Application

**Production Build:**
```bash
# Build UI and Electron app
npm run build

# Package for distribution
npm run package:win   # Windows
npm run package:mac   # macOS
npm run package:linux # Linux
```

**Build Status:** âœ… All builds passing
- UI Build: ~8s
- Electron Build: Complete
- TypeScript: No errors
- Bundle Size: 1.38 MB (356 KB gzipped)

**For detailed build information, see:** [BUILD_REPORT.md](BUILD_REPORT.md)


---

## ğŸ¯ Future Roadmap (Post-Launch Enhancements)

### ğŸ“Š Visual Roadmap

| Phase | Feature | Status | Description |
|-------|---------|--------|-------------|
| **Phase 1** | Advanced Camera Movements | ğŸ”œ Planned | Bezier curves and complex transitions |
| **Phase 1** | Multi-format Export | ğŸ”œ Planned | MP4 generation from video plans |
| **Phase 2** | Collaborative Features | ğŸ“‹ Backlog | Multi-user project management |
| **Phase 2** | Performance Optimization | ğŸ“‹ Backlog | Parallel processing and caching |
| **Phase 3** | Plugin Architecture | ğŸ“‹ Backlog | Custom engine extensions |
| **Phase 3** | Cloud Deployment | ğŸ“‹ Backlog | Scalable cloud infrastructure |
| **Phase 4** | Real-time Monitoring | ğŸ“‹ Backlog | Enhanced monitoring with alerting |
| **Phase 4** | Multi-character Scenes | ğŸ“‹ Backlog | Advanced scene composition |
| **Phase 5** | Studio Integration | ğŸ“‹ Backlog | Enterprise deployment and scaling |

### ğŸ“‹ Milestone List

1. **v0.2.0** - Advanced Camera Movements & Transitions
2. **v0.3.0** - Multi-format Export (MP4)
3. **v0.4.0** - Collaborative Features
4. **v0.5.0** - Performance Optimization
5. **v1.0.0** - Plugin Architecture & Cloud Ready

---

**Planned Features:**
- Advanced Camera Movements: Bezier curves and complex transitions
- Multi-format Export: MP4 generation from video plans
- Collaborative Features: Multi-user project management
- Performance Optimization: Parallel processing and caching
- Plugin Architecture: Custom engine extensions
- Cloud Deployment: Scalable cloud infrastructure
- Real-time Monitoring Dashboard: Enhanced monitoring with alerting
- Multi-character Scenes: Advanced scene composition
- Professional Studio Integration: Enterprise deployment and scaling

---

## ğŸ“š Documentation

### Getting Started
- [Quick Start Guide](docs/COMFYUI_QUICK_START.md) - ComfyUI setup in 2 minutes
- [Documentation Index](DOCUMENTATION_INDEX.md) - ğŸ“‘ **START HERE** - Complete documentation navigation
- [Quick Reference](QUICK_REFERENCE.md) - Common commands and workflows

### Build & Development
- [Build Success Summary](BUILD_SUCCESS_SUMMARY.md) - âœ… Latest build status (Jan 23, 2026)
- [Build Report](BUILD_REPORT.md) - Detailed build analysis and metrics
- [Test Fixes](FIX_TESTS.md) - Test improvements and known issues
- [TODO List](TODO.md) - Master TODO and task tracking
- [Release Notes](RELEASE_NOTES_2026_01_23.md) - Latest release information
- [Changelog](CHANGELOG.md) - Version history

### Technical Documentation
- [Technical Guide](documentation/TECHNICAL_GUIDE.md) - Architecture and implementation
- [API Reference](documentation/api/) - API documentation
- [Troubleshooting](documentation/TROUBLESHOOTING.md) - Common issues and solutions
- [Project Index](INDEX.md) - Complete project structure



---

## ğŸ… Built for Hackathon 2026

**Team:** StoryCore-Engine Development Team  
**Duration:** 210+ hours  
**Focus:** Coherence-first, measurable multimodal pipeline  
**Result:** Production-ready system with professional interfaces

*Redefining how creators interact with multimodal AI through guaranteed visual coherence and autonomous quality control.*
