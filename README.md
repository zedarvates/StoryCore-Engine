# ğŸ¬ StoryCore Engine
### The Self-Correcting Multimodal Production Pipeline

**From Script to Screen in Minutes â€” With Visual Coherence**

![Hackathon 2026](https://img.shields.io/badge/Hackathon-2026-blue) ![Python](https://img.shields.io/badge/Python-3.11+-green) ![React](https://img.shields.io/badge/React-18+-blue) ![ComfyUI](https://img.shields.io/badge/ComfyUI-Ready-orange) ![Deterministic AI](https://img.shields.io/badge/Deterministic-AI-purple) ![Security](https://img.shields.io/badge/Security-Validated-green) ![Local Processing](https://img.shields.io/badge/Local-Processing-blue)
![License](https://img.shields.io/github/license/zedarvates/StoryCore-Engine)

> **From Script to Screen in Minutes** - Self-correcting multimodal video pipeline with guaranteed visual coherence. 100% local processing. Data sovereignty.

---

![StoryCore-Engine Preview](assets/Screenshot-2026-02-15-060825.png)

---

## ğŸŒŸ A Message from the Creator

StoryCore is more than just a pipeline. Itâ€™s a system that lets you control ComfyUI or other tools through addâ€‘ons. It helps you organize your entire workflow for video creation â€” from the written story, to the script, to the dialogue.

> "The future of the internet? And of cinema? Itâ€™s onâ€‘demand videos built according to peopleâ€™s tastes. According to each customer. Directly on their TV. Basically, itâ€™s instant, madeâ€‘toâ€‘order cinema."

I wanted to create a tool that modernizes longâ€‘form video production without losing the soul of the craft. We start from the classic storyboard methodsâ€”the ones that shaped generations of creatorsâ€”and we bring them into the present with the tools of our era.

**This isn't just another AI generator.** It's a complete production pipeline: storyboard, visual coherence, narrative continuity, scene organization, character tracking, location consistency. The system remembers the entire project, just like a full team dedicated to artistic supervision.

But above all, it **respects the creators**. The goal is not to replace artists, but to give them back time, freedom, and control. AI handles the repetitive tasks, while humans keep the vision, the emotion, and the direction.

And everything runs **locally**. Your data, your images, your scripts, your industrial secretsâ€”everything stays on your machine. It's a sovereign tool, designed for studios, agencies, and independent creators who must protect their work.

---

## ğŸ¯ Why StoryCore?

### Competitive Advantages

| Benefit | Impact |
| :--- | :--- |
| **100% Local Processing** | Data secured on your machine, no leaks. |
| **Visual Coherence** | Consistent style across all scenes and shots. |
| **Self-Correcting Pipeline** | Guaranteed quality without manual intervention. |
| **Native ComfyUI Integration** | Optimized professional workflows. |
| **Data Sovereignty** | No cloud, no subscription risks, full ownership. |

**Cost Reduction**: From a team of 30 to 6-8 creators.
**Time Saving**: From script to screen in minutes, not months.

---

## ğŸš€ Concrete Use Cases

| Content Type | Benefit | Estimated Time |
| :--- | :--- | :--- |
| **Scientific Documentaries** | Guaranteed visual accuracy & fact-checking. | 20-30 min |
| **Indie Short Films** | Stylistic consistency & narrative flow. | 15-25 min |
| **Educational Content** | Professional quality & rapid iteration. | 10-20 min |
| **Corporate Presentations** | Consistent branding & private data handling. | 5-15 min |

### Workflow

```mermaid
graph LR
    A --> B[âœï¸ Script] --> C[âœ… Storyboard]
    C --> D[ğŸ¨ Visual Gen]
    D --> E[ğŸ¬ Editing]
    E --> F[ğŸ“¦ Export]
```

---

## ğŸ“‹ System Requirements

### Minimum Hardware
- **GPU**: NVIDIA RTX 3060 with 12GB VRAM (RTX 4090+ recommended for speed)
- **RAM**: 32GB system memory
- **Storage**: ~500GB SSD (fast NVMe recommended)
- **OS**: Windows 10/11 (WSL2 supported), Linux

*Note: Generating a single high-quality image can take minutes on lower-end hardware. Video generation is compute-intensive.*

---

## âš¡ Quick Start

### Installation in 5 Minutes

1.  **Clone the repository**
    ```bash
    git clone https://github.com/zedarvates/StoryCore-Engine.git
    cd storycore-engine
    ```

2.  **Install dependencies**
    ```bash
    pip install -r requirements.txt
    npm install
    ```

3.  **Install ComfyUI (Optional but Recommended)**
    - Download from [ComfyUI GitHub](https://github.com/comfyanonymous/ComfyUI)
    - Default port: `8188`

4.  **Start the Engine**
    ```bash
    python storycore.py
    ```

### Video Demo
[![StoryCore Presentation Video]](https://www.youtube.com/watch?v=P0K7DueyICo)

---

## ğŸ“¸ Interface

![StoryCore Interface](assets/Screenshot-2026-02-15-060805.png)

![StoryCore Dashboard](assets/Screenshot-2026-02-15-060909.png)

![StoryCore Editor](assets/Screenshot-2026-02-15-060938.png)

---

## âœ¨ Key Features

### ğŸ¬ Video Generation
- **Visual Coherence System**: Master Coherence Sheet ensures consistent style.
- **Total Recall (Living Protocol)**: Persistent neural memory that captures stylistic decisions, character facts, and production rules as they emerge during chat or creation.
- **Multimodal Vision Analysis**: Native support for analyzing reference images to extract visual archetypes, atmospheres, and cinematic styles.
- **Multi-Model Support**: Flux, SDXL, NewBie, Qwen 2.5-VL, HunyuanVideo, Wan Video.
- **Self-Correcting**: Automatic quality detection and auto-fix capability.

### âœï¸ Story & Content Creation
- **Augmented Creation Engine**: Significant upgrade in AI-driven generation for Characters, Locations, Objects, and Worlds with automatic detail enrichment.
- **Neural Scenario Planning**: Automated breakdown of storyboards into optimized shot sequences with technical rig metadata.
- **Project Genesis**: One-shot project creation from natural language descriptions, including automatic universe building.
- **AI Dialogue**: Natural voice generation with emotion control.
- **Background Music**: Automatic composition based on scene mood.
- **Sound Effects**: Integrated SFX library and synchronization.

### ğŸ› ï¸ Production Tools
- **Neural Production Assistant**: AI-driven directorial advice and "Neural Manufacturing" workflow.
- **Neural Brain**: Dedicated interface for managing persistent project insights and distilling "Living Protocols."
- **Production Ledger**: A verified manifest of all AI-generated assets (Character Sheets, Style Guides, Lore fragments).
- **Director Rig Metadata**: High-fidelity technical metadata for shots (Lens geometry, Sensor look, Emotional intensity).
- **World Aesthetic Registry**: Persistent visual intent registry (Colors, Vibe, Artistic Signature) integrated with the World Genesis engine.
- **Production Guide**: Comprehensive shot recap with Technical Rig metadata (Lens, Sensor, Emotion).

### ğŸ—ï¸ Architecture
- **100% Local**: No external dependencies for core processing.
- **Extensible**: Robust Add-on system for custom tools.
- **Resilient**: Circuit breakers and retry mechanisms for long-running tasks.
- **Agent-Ready**: Event-driven communication for AI assistants.

---

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TD
    Input[ğŸ“ Input Script/Prompt] --> StoryEngine
    
    subgraph StoryEngine [ğŸ§  Story Engine]
        LLM[LLM Processing - Ollama]
        Scene[Scene Breakdown]
        Char[Character Dev]
    end
    
    StoryEngine --> VisualPlanning
    
    subgraph VisualPlanning [ğŸ¨ Visual Planning]
        Grid[Visual Coherence Grid]
        Shot[Shot Planning]
    end
    
    VisualPlanning --> Production
    
    subgraph Production [ğŸ¬ Production Pipeline]
        ImgGen[Image Gen]
        VidGen[Video Gen]
        AudioGen[Audio Gen]
        AutoFix[Quality Check & Auto-fix]
    end
    
    Production --> Export[ğŸ“¦ Export]
```

---

## ğŸ”§ For Developers

### API & SDK
- **REST API**: FastAPI backend for integration.
- **WebSocket**: Real-time communication for UI updates.
- **Python SDK**: Easy integration for custom scripts.
- **CLI Tools**: Full automation capabilities.

### Documentation
- **[Quick Start](documentation/user_guide/comfyui_integration/COMFYUI_QUICK_START.md)** - Setup guide
- **[API Reference](documentation/api_reference/README.md)** - Full API docs
- **[Technical Guide](documentation/TECHNICAL_GUIDE.md)** - Deep dive into architecture
- **[Contributing](CONTRIBUTING.md)** - Join the project

---

## ğŸ—ºï¸ Roadmap 2026

| Phase | Feature | Status |
| :--- | :--- | :--- |
| **Q1 2026** | Neural Production Assistant | âœ… Completed |
| **Q1 2026** | Total Recall AI Memory (Living Protocol) | âœ… Completed |
| **Q1 2026** | Multimodal Vision Integration | âœ… Completed |
| **Q1 2026** | World Aesthetic Registry & Genesis | âœ… Completed |
| **Q1 2026** | Augmented Content Creation Engine | âœ… Completed |
| **Q1 2026** | Advanced Camera Movements & Rigging | âœ… Completed |
| **Q2 2026** | Image Generation Dialog Enhancement | ğŸ”„ In Progress |
| **Q2 2026** | Multi-format Export (MP4/WebM) | ğŸ”œ Planned |
| **Q3 2026** | Collaborative Features | ğŸ“‹ Backlog |
| **Q4 2026** | Cloud Deployment Options | ğŸ“‹ Backlog |

---

## ğŸ† Built for Hackathon 2026

**Team**: StoryCore-Engine Development Team
**Duration**: 210+ hours
**Focus**: Coherence-first, measurable multimodal pipeline
**Result**: Production-ready system with professional interfaces

*Redefining how creators interact with multimodal AI through guaranteed visual coherence and autonomous quality control.*
